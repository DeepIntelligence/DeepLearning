// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: DeepLearning.proto

#ifndef PROTOBUF_DeepLearning_2eproto__INCLUDED
#define PROTOBUF_DeepLearning_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 2006000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 2006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

// Internal implementation detail -- do not call these.
void  protobuf_AddDesc_DeepLearning_2eproto();
void protobuf_AssignDesc_DeepLearning_2eproto();
void protobuf_ShutdownFile_DeepLearning_2eproto();

class NeuralNetParameter;
class LayerStructParameter;
class TrainingParameter;

enum LayerStructParameter_ActivationType {
  LayerStructParameter_ActivationType_sigmoid = 1,
  LayerStructParameter_ActivationType_tanh = 2,
  LayerStructParameter_ActivationType_linear = 3,
  LayerStructParameter_ActivationType_softmax = 4
};
bool LayerStructParameter_ActivationType_IsValid(int value);
const LayerStructParameter_ActivationType LayerStructParameter_ActivationType_ActivationType_MIN = LayerStructParameter_ActivationType_sigmoid;
const LayerStructParameter_ActivationType LayerStructParameter_ActivationType_ActivationType_MAX = LayerStructParameter_ActivationType_softmax;
const int LayerStructParameter_ActivationType_ActivationType_ARRAYSIZE = LayerStructParameter_ActivationType_ActivationType_MAX + 1;

const ::google::protobuf::EnumDescriptor* LayerStructParameter_ActivationType_descriptor();
inline const ::std::string& LayerStructParameter_ActivationType_Name(LayerStructParameter_ActivationType value) {
  return ::google::protobuf::internal::NameOfEnum(
    LayerStructParameter_ActivationType_descriptor(), value);
}
inline bool LayerStructParameter_ActivationType_Parse(
    const ::std::string& name, LayerStructParameter_ActivationType* value) {
  return ::google::protobuf::internal::ParseNamedEnum<LayerStructParameter_ActivationType>(
    LayerStructParameter_ActivationType_descriptor(), name, value);
}
// ===================================================================

class NeuralNetParameter : public ::google::protobuf::Message {
 public:
  NeuralNetParameter();
  virtual ~NeuralNetParameter();

  NeuralNetParameter(const NeuralNetParameter& from);

  inline NeuralNetParameter& operator=(const NeuralNetParameter& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NeuralNetParameter& default_instance();

  void Swap(NeuralNetParameter* other);

  // implements Message ----------------------------------------------

  NeuralNetParameter* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NeuralNetParameter& from);
  void MergeFrom(const NeuralNetParameter& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  inline bool has_name() const;
  inline void clear_name();
  static const int kNameFieldNumber = 1;
  inline const ::std::string& name() const;
  inline void set_name(const ::std::string& value);
  inline void set_name(const char* value);
  inline void set_name(const char* value, size_t size);
  inline ::std::string* mutable_name();
  inline ::std::string* release_name();
  inline void set_allocated_name(::std::string* name);

  // optional string type = 2;
  inline bool has_type() const;
  inline void clear_type();
  static const int kTypeFieldNumber = 2;
  inline const ::std::string& type() const;
  inline void set_type(const ::std::string& value);
  inline void set_type(const char* value);
  inline void set_type(const char* value, size_t size);
  inline ::std::string* mutable_type();
  inline ::std::string* release_type();
  inline void set_allocated_type(::std::string* type);

  // repeated .LayerStructParameter layerStruct = 100;
  inline int layerstruct_size() const;
  inline void clear_layerstruct();
  static const int kLayerStructFieldNumber = 100;
  inline const ::LayerStructParameter& layerstruct(int index) const;
  inline ::LayerStructParameter* mutable_layerstruct(int index);
  inline ::LayerStructParameter* add_layerstruct();
  inline const ::google::protobuf::RepeatedPtrField< ::LayerStructParameter >&
      layerstruct() const;
  inline ::google::protobuf::RepeatedPtrField< ::LayerStructParameter >*
      mutable_layerstruct();

  // optional .TrainingParameter trainingParameter = 101;
  inline bool has_trainingparameter() const;
  inline void clear_trainingparameter();
  static const int kTrainingParameterFieldNumber = 101;
  inline const ::TrainingParameter& trainingparameter() const;
  inline ::TrainingParameter* mutable_trainingparameter();
  inline ::TrainingParameter* release_trainingparameter();
  inline void set_allocated_trainingparameter(::TrainingParameter* trainingparameter);

  // @@protoc_insertion_point(class_scope:NeuralNetParameter)
 private:
  inline void set_has_name();
  inline void clear_has_name();
  inline void set_has_type();
  inline void clear_has_type();
  inline void set_has_trainingparameter();
  inline void clear_has_trainingparameter();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  ::std::string* name_;
  ::std::string* type_;
  ::google::protobuf::RepeatedPtrField< ::LayerStructParameter > layerstruct_;
  ::TrainingParameter* trainingparameter_;
  friend void  protobuf_AddDesc_DeepLearning_2eproto();
  friend void protobuf_AssignDesc_DeepLearning_2eproto();
  friend void protobuf_ShutdownFile_DeepLearning_2eproto();

  void InitAsDefaultInstance();
  static NeuralNetParameter* default_instance_;
};
// -------------------------------------------------------------------

class LayerStructParameter : public ::google::protobuf::Message {
 public:
  LayerStructParameter();
  virtual ~LayerStructParameter();

  LayerStructParameter(const LayerStructParameter& from);

  inline LayerStructParameter& operator=(const LayerStructParameter& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const LayerStructParameter& default_instance();

  void Swap(LayerStructParameter* other);

  // implements Message ----------------------------------------------

  LayerStructParameter* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const LayerStructParameter& from);
  void MergeFrom(const LayerStructParameter& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  typedef LayerStructParameter_ActivationType ActivationType;
  static const ActivationType sigmoid = LayerStructParameter_ActivationType_sigmoid;
  static const ActivationType tanh = LayerStructParameter_ActivationType_tanh;
  static const ActivationType linear = LayerStructParameter_ActivationType_linear;
  static const ActivationType softmax = LayerStructParameter_ActivationType_softmax;
  static inline bool ActivationType_IsValid(int value) {
    return LayerStructParameter_ActivationType_IsValid(value);
  }
  static const ActivationType ActivationType_MIN =
    LayerStructParameter_ActivationType_ActivationType_MIN;
  static const ActivationType ActivationType_MAX =
    LayerStructParameter_ActivationType_ActivationType_MAX;
  static const int ActivationType_ARRAYSIZE =
    LayerStructParameter_ActivationType_ActivationType_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  ActivationType_descriptor() {
    return LayerStructParameter_ActivationType_descriptor();
  }
  static inline const ::std::string& ActivationType_Name(ActivationType value) {
    return LayerStructParameter_ActivationType_Name(value);
  }
  static inline bool ActivationType_Parse(const ::std::string& name,
      ActivationType* value) {
    return LayerStructParameter_ActivationType_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // optional int32 inputDim = 1;
  inline bool has_inputdim() const;
  inline void clear_inputdim();
  static const int kInputDimFieldNumber = 1;
  inline ::google::protobuf::int32 inputdim() const;
  inline void set_inputdim(::google::protobuf::int32 value);

  // optional int32 outputDim = 2;
  inline bool has_outputdim() const;
  inline void clear_outputdim();
  static const int kOutputDimFieldNumber = 2;
  inline ::google::protobuf::int32 outputdim() const;
  inline void set_outputdim(::google::protobuf::int32 value);

  // optional .LayerStructParameter.ActivationType activationType = 3;
  inline bool has_activationtype() const;
  inline void clear_activationtype();
  static const int kActivationTypeFieldNumber = 3;
  inline ::LayerStructParameter_ActivationType activationtype() const;
  inline void set_activationtype(::LayerStructParameter_ActivationType value);

  // optional string name = 4;
  inline bool has_name() const;
  inline void clear_name();
  static const int kNameFieldNumber = 4;
  inline const ::std::string& name() const;
  inline void set_name(const ::std::string& value);
  inline void set_name(const char* value);
  inline void set_name(const char* value, size_t size);
  inline ::std::string* mutable_name();
  inline ::std::string* release_name();
  inline void set_allocated_name(::std::string* name);

  // optional string type = 5;
  inline bool has_type() const;
  inline void clear_type();
  static const int kTypeFieldNumber = 5;
  inline const ::std::string& type() const;
  inline void set_type(const ::std::string& value);
  inline void set_type(const char* value);
  inline void set_type(const char* value, size_t size);
  inline ::std::string* mutable_type();
  inline ::std::string* release_type();
  inline void set_allocated_type(::std::string* type);

  // @@protoc_insertion_point(class_scope:LayerStructParameter)
 private:
  inline void set_has_inputdim();
  inline void clear_has_inputdim();
  inline void set_has_outputdim();
  inline void clear_has_outputdim();
  inline void set_has_activationtype();
  inline void clear_has_activationtype();
  inline void set_has_name();
  inline void clear_has_name();
  inline void set_has_type();
  inline void clear_has_type();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  ::google::protobuf::int32 inputdim_;
  ::google::protobuf::int32 outputdim_;
  ::std::string* name_;
  ::std::string* type_;
  int activationtype_;
  friend void  protobuf_AddDesc_DeepLearning_2eproto();
  friend void protobuf_AssignDesc_DeepLearning_2eproto();
  friend void protobuf_ShutdownFile_DeepLearning_2eproto();

  void InitAsDefaultInstance();
  static LayerStructParameter* default_instance_;
};
// -------------------------------------------------------------------

class TrainingParameter : public ::google::protobuf::Message {
 public:
  TrainingParameter();
  virtual ~TrainingParameter();

  TrainingParameter(const TrainingParameter& from);

  inline TrainingParameter& operator=(const TrainingParameter& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const TrainingParameter& default_instance();

  void Swap(TrainingParameter* other);

  // implements Message ----------------------------------------------

  TrainingParameter* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const TrainingParameter& from);
  void MergeFrom(const TrainingParameter& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional double learningRate = 1;
  inline bool has_learningrate() const;
  inline void clear_learningrate();
  static const int kLearningRateFieldNumber = 1;
  inline double learningrate() const;
  inline void set_learningrate(double value);

  // optional int32 maxIter = 2;
  inline bool has_maxiter() const;
  inline void clear_maxiter();
  static const int kMaxIterFieldNumber = 2;
  inline ::google::protobuf::int32 maxiter() const;
  inline void set_maxiter(::google::protobuf::int32 value);

  // @@protoc_insertion_point(class_scope:TrainingParameter)
 private:
  inline void set_has_learningrate();
  inline void clear_has_learningrate();
  inline void set_has_maxiter();
  inline void clear_has_maxiter();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  double learningrate_;
  ::google::protobuf::int32 maxiter_;
  friend void  protobuf_AddDesc_DeepLearning_2eproto();
  friend void protobuf_AssignDesc_DeepLearning_2eproto();
  friend void protobuf_ShutdownFile_DeepLearning_2eproto();

  void InitAsDefaultInstance();
  static TrainingParameter* default_instance_;
};
// ===================================================================


// ===================================================================

// NeuralNetParameter

// optional string name = 1;
inline bool NeuralNetParameter::has_name() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NeuralNetParameter::set_has_name() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NeuralNetParameter::clear_has_name() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NeuralNetParameter::clear_name() {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_->clear();
  }
  clear_has_name();
}
inline const ::std::string& NeuralNetParameter::name() const {
  // @@protoc_insertion_point(field_get:NeuralNetParameter.name)
  return *name_;
}
inline void NeuralNetParameter::set_name(const ::std::string& value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set:NeuralNetParameter.name)
}
inline void NeuralNetParameter::set_name(const char* value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set_char:NeuralNetParameter.name)
}
inline void NeuralNetParameter::set_name(const char* value, size_t size) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:NeuralNetParameter.name)
}
inline ::std::string* NeuralNetParameter::mutable_name() {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:NeuralNetParameter.name)
  return name_;
}
inline ::std::string* NeuralNetParameter::release_name() {
  clear_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = name_;
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void NeuralNetParameter::set_allocated_name(::std::string* name) {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete name_;
  }
  if (name) {
    set_has_name();
    name_ = name;
  } else {
    clear_has_name();
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:NeuralNetParameter.name)
}

// optional string type = 2;
inline bool NeuralNetParameter::has_type() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NeuralNetParameter::set_has_type() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NeuralNetParameter::clear_has_type() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NeuralNetParameter::clear_type() {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_->clear();
  }
  clear_has_type();
}
inline const ::std::string& NeuralNetParameter::type() const {
  // @@protoc_insertion_point(field_get:NeuralNetParameter.type)
  return *type_;
}
inline void NeuralNetParameter::set_type(const ::std::string& value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set:NeuralNetParameter.type)
}
inline void NeuralNetParameter::set_type(const char* value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set_char:NeuralNetParameter.type)
}
inline void NeuralNetParameter::set_type(const char* value, size_t size) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:NeuralNetParameter.type)
}
inline ::std::string* NeuralNetParameter::mutable_type() {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:NeuralNetParameter.type)
  return type_;
}
inline ::std::string* NeuralNetParameter::release_type() {
  clear_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = type_;
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void NeuralNetParameter::set_allocated_type(::std::string* type) {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete type_;
  }
  if (type) {
    set_has_type();
    type_ = type;
  } else {
    clear_has_type();
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:NeuralNetParameter.type)
}

// repeated .LayerStructParameter layerStruct = 100;
inline int NeuralNetParameter::layerstruct_size() const {
  return layerstruct_.size();
}
inline void NeuralNetParameter::clear_layerstruct() {
  layerstruct_.Clear();
}
inline const ::LayerStructParameter& NeuralNetParameter::layerstruct(int index) const {
  // @@protoc_insertion_point(field_get:NeuralNetParameter.layerStruct)
  return layerstruct_.Get(index);
}
inline ::LayerStructParameter* NeuralNetParameter::mutable_layerstruct(int index) {
  // @@protoc_insertion_point(field_mutable:NeuralNetParameter.layerStruct)
  return layerstruct_.Mutable(index);
}
inline ::LayerStructParameter* NeuralNetParameter::add_layerstruct() {
  // @@protoc_insertion_point(field_add:NeuralNetParameter.layerStruct)
  return layerstruct_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::LayerStructParameter >&
NeuralNetParameter::layerstruct() const {
  // @@protoc_insertion_point(field_list:NeuralNetParameter.layerStruct)
  return layerstruct_;
}
inline ::google::protobuf::RepeatedPtrField< ::LayerStructParameter >*
NeuralNetParameter::mutable_layerstruct() {
  // @@protoc_insertion_point(field_mutable_list:NeuralNetParameter.layerStruct)
  return &layerstruct_;
}

// optional .TrainingParameter trainingParameter = 101;
inline bool NeuralNetParameter::has_trainingparameter() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void NeuralNetParameter::set_has_trainingparameter() {
  _has_bits_[0] |= 0x00000008u;
}
inline void NeuralNetParameter::clear_has_trainingparameter() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void NeuralNetParameter::clear_trainingparameter() {
  if (trainingparameter_ != NULL) trainingparameter_->::TrainingParameter::Clear();
  clear_has_trainingparameter();
}
inline const ::TrainingParameter& NeuralNetParameter::trainingparameter() const {
  // @@protoc_insertion_point(field_get:NeuralNetParameter.trainingParameter)
  return trainingparameter_ != NULL ? *trainingparameter_ : *default_instance_->trainingparameter_;
}
inline ::TrainingParameter* NeuralNetParameter::mutable_trainingparameter() {
  set_has_trainingparameter();
  if (trainingparameter_ == NULL) trainingparameter_ = new ::TrainingParameter;
  // @@protoc_insertion_point(field_mutable:NeuralNetParameter.trainingParameter)
  return trainingparameter_;
}
inline ::TrainingParameter* NeuralNetParameter::release_trainingparameter() {
  clear_has_trainingparameter();
  ::TrainingParameter* temp = trainingparameter_;
  trainingparameter_ = NULL;
  return temp;
}
inline void NeuralNetParameter::set_allocated_trainingparameter(::TrainingParameter* trainingparameter) {
  delete trainingparameter_;
  trainingparameter_ = trainingparameter;
  if (trainingparameter) {
    set_has_trainingparameter();
  } else {
    clear_has_trainingparameter();
  }
  // @@protoc_insertion_point(field_set_allocated:NeuralNetParameter.trainingParameter)
}

// -------------------------------------------------------------------

// LayerStructParameter

// optional int32 inputDim = 1;
inline bool LayerStructParameter::has_inputdim() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void LayerStructParameter::set_has_inputdim() {
  _has_bits_[0] |= 0x00000001u;
}
inline void LayerStructParameter::clear_has_inputdim() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void LayerStructParameter::clear_inputdim() {
  inputdim_ = 0;
  clear_has_inputdim();
}
inline ::google::protobuf::int32 LayerStructParameter::inputdim() const {
  // @@protoc_insertion_point(field_get:LayerStructParameter.inputDim)
  return inputdim_;
}
inline void LayerStructParameter::set_inputdim(::google::protobuf::int32 value) {
  set_has_inputdim();
  inputdim_ = value;
  // @@protoc_insertion_point(field_set:LayerStructParameter.inputDim)
}

// optional int32 outputDim = 2;
inline bool LayerStructParameter::has_outputdim() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void LayerStructParameter::set_has_outputdim() {
  _has_bits_[0] |= 0x00000002u;
}
inline void LayerStructParameter::clear_has_outputdim() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void LayerStructParameter::clear_outputdim() {
  outputdim_ = 0;
  clear_has_outputdim();
}
inline ::google::protobuf::int32 LayerStructParameter::outputdim() const {
  // @@protoc_insertion_point(field_get:LayerStructParameter.outputDim)
  return outputdim_;
}
inline void LayerStructParameter::set_outputdim(::google::protobuf::int32 value) {
  set_has_outputdim();
  outputdim_ = value;
  // @@protoc_insertion_point(field_set:LayerStructParameter.outputDim)
}

// optional .LayerStructParameter.ActivationType activationType = 3;
inline bool LayerStructParameter::has_activationtype() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void LayerStructParameter::set_has_activationtype() {
  _has_bits_[0] |= 0x00000004u;
}
inline void LayerStructParameter::clear_has_activationtype() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void LayerStructParameter::clear_activationtype() {
  activationtype_ = 1;
  clear_has_activationtype();
}
inline ::LayerStructParameter_ActivationType LayerStructParameter::activationtype() const {
  // @@protoc_insertion_point(field_get:LayerStructParameter.activationType)
  return static_cast< ::LayerStructParameter_ActivationType >(activationtype_);
}
inline void LayerStructParameter::set_activationtype(::LayerStructParameter_ActivationType value) {
  assert(::LayerStructParameter_ActivationType_IsValid(value));
  set_has_activationtype();
  activationtype_ = value;
  // @@protoc_insertion_point(field_set:LayerStructParameter.activationType)
}

// optional string name = 4;
inline bool LayerStructParameter::has_name() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void LayerStructParameter::set_has_name() {
  _has_bits_[0] |= 0x00000008u;
}
inline void LayerStructParameter::clear_has_name() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void LayerStructParameter::clear_name() {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_->clear();
  }
  clear_has_name();
}
inline const ::std::string& LayerStructParameter::name() const {
  // @@protoc_insertion_point(field_get:LayerStructParameter.name)
  return *name_;
}
inline void LayerStructParameter::set_name(const ::std::string& value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set:LayerStructParameter.name)
}
inline void LayerStructParameter::set_name(const char* value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set_char:LayerStructParameter.name)
}
inline void LayerStructParameter::set_name(const char* value, size_t size) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:LayerStructParameter.name)
}
inline ::std::string* LayerStructParameter::mutable_name() {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:LayerStructParameter.name)
  return name_;
}
inline ::std::string* LayerStructParameter::release_name() {
  clear_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = name_;
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void LayerStructParameter::set_allocated_name(::std::string* name) {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete name_;
  }
  if (name) {
    set_has_name();
    name_ = name;
  } else {
    clear_has_name();
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:LayerStructParameter.name)
}

// optional string type = 5;
inline bool LayerStructParameter::has_type() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void LayerStructParameter::set_has_type() {
  _has_bits_[0] |= 0x00000010u;
}
inline void LayerStructParameter::clear_has_type() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void LayerStructParameter::clear_type() {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_->clear();
  }
  clear_has_type();
}
inline const ::std::string& LayerStructParameter::type() const {
  // @@protoc_insertion_point(field_get:LayerStructParameter.type)
  return *type_;
}
inline void LayerStructParameter::set_type(const ::std::string& value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set:LayerStructParameter.type)
}
inline void LayerStructParameter::set_type(const char* value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set_char:LayerStructParameter.type)
}
inline void LayerStructParameter::set_type(const char* value, size_t size) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:LayerStructParameter.type)
}
inline ::std::string* LayerStructParameter::mutable_type() {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:LayerStructParameter.type)
  return type_;
}
inline ::std::string* LayerStructParameter::release_type() {
  clear_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = type_;
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void LayerStructParameter::set_allocated_type(::std::string* type) {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete type_;
  }
  if (type) {
    set_has_type();
    type_ = type;
  } else {
    clear_has_type();
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:LayerStructParameter.type)
}

// -------------------------------------------------------------------

// TrainingParameter

// optional double learningRate = 1;
inline bool TrainingParameter::has_learningrate() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void TrainingParameter::set_has_learningrate() {
  _has_bits_[0] |= 0x00000001u;
}
inline void TrainingParameter::clear_has_learningrate() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void TrainingParameter::clear_learningrate() {
  learningrate_ = 0;
  clear_has_learningrate();
}
inline double TrainingParameter::learningrate() const {
  // @@protoc_insertion_point(field_get:TrainingParameter.learningRate)
  return learningrate_;
}
inline void TrainingParameter::set_learningrate(double value) {
  set_has_learningrate();
  learningrate_ = value;
  // @@protoc_insertion_point(field_set:TrainingParameter.learningRate)
}

// optional int32 maxIter = 2;
inline bool TrainingParameter::has_maxiter() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void TrainingParameter::set_has_maxiter() {
  _has_bits_[0] |= 0x00000002u;
}
inline void TrainingParameter::clear_has_maxiter() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void TrainingParameter::clear_maxiter() {
  maxiter_ = 0;
  clear_has_maxiter();
}
inline ::google::protobuf::int32 TrainingParameter::maxiter() const {
  // @@protoc_insertion_point(field_get:TrainingParameter.maxIter)
  return maxiter_;
}
inline void TrainingParameter::set_maxiter(::google::protobuf::int32 value) {
  set_has_maxiter();
  maxiter_ = value;
  // @@protoc_insertion_point(field_set:TrainingParameter.maxIter)
}


// @@protoc_insertion_point(namespace_scope)

#ifndef SWIG
namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::LayerStructParameter_ActivationType> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::LayerStructParameter_ActivationType>() {
  return ::LayerStructParameter_ActivationType_descriptor();
}

}  // namespace google
}  // namespace protobuf
#endif  // SWIG

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_DeepLearning_2eproto__INCLUDED
