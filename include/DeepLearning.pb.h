// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: DeepLearning.proto

#ifndef PROTOBUF_DeepLearning_2eproto__INCLUDED
#define PROTOBUF_DeepLearning_2eproto__INCLUDED

#include <string>

#include <google/protobuf/stubs/common.h>

#if GOOGLE_PROTOBUF_VERSION < 2006000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please update
#error your headers.
#endif
#if 2006001 < GOOGLE_PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers.  Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/message.h>
#include <google/protobuf/repeated_field.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/generated_enum_reflection.h>
#include <google/protobuf/unknown_field_set.h>
// @@protoc_insertion_point(includes)

namespace DeepLearning {

// Internal implementation detail -- do not call these.
void  protobuf_AddDesc_DeepLearning_2eproto();
void protobuf_AssignDesc_DeepLearning_2eproto();
void protobuf_ShutdownFile_DeepLearning_2eproto();

class NeuralNetParameter;
class LayerStructParameter;
class NeuralNetTrainingParameter;

enum LayerStructParameter_ActivationType {
  LayerStructParameter_ActivationType_sigmoid = 1,
  LayerStructParameter_ActivationType_tanh = 2,
  LayerStructParameter_ActivationType_linear = 3,
  LayerStructParameter_ActivationType_softmax = 4
};
bool LayerStructParameter_ActivationType_IsValid(int value);
const LayerStructParameter_ActivationType LayerStructParameter_ActivationType_ActivationType_MIN = LayerStructParameter_ActivationType_sigmoid;
const LayerStructParameter_ActivationType LayerStructParameter_ActivationType_ActivationType_MAX = LayerStructParameter_ActivationType_softmax;
const int LayerStructParameter_ActivationType_ActivationType_ARRAYSIZE = LayerStructParameter_ActivationType_ActivationType_MAX + 1;

const ::google::protobuf::EnumDescriptor* LayerStructParameter_ActivationType_descriptor();
inline const ::std::string& LayerStructParameter_ActivationType_Name(LayerStructParameter_ActivationType value) {
  return ::google::protobuf::internal::NameOfEnum(
    LayerStructParameter_ActivationType_descriptor(), value);
}
inline bool LayerStructParameter_ActivationType_Parse(
    const ::std::string& name, LayerStructParameter_ActivationType* value) {
  return ::google::protobuf::internal::ParseNamedEnum<LayerStructParameter_ActivationType>(
    LayerStructParameter_ActivationType_descriptor(), name, value);
}
// ===================================================================

class NeuralNetParameter : public ::google::protobuf::Message {
 public:
  NeuralNetParameter();
  virtual ~NeuralNetParameter();

  NeuralNetParameter(const NeuralNetParameter& from);

  inline NeuralNetParameter& operator=(const NeuralNetParameter& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NeuralNetParameter& default_instance();

  void Swap(NeuralNetParameter* other);

  // implements Message ----------------------------------------------

  NeuralNetParameter* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NeuralNetParameter& from);
  void MergeFrom(const NeuralNetParameter& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional string name = 1;
  inline bool has_name() const;
  inline void clear_name();
  static const int kNameFieldNumber = 1;
  inline const ::std::string& name() const;
  inline void set_name(const ::std::string& value);
  inline void set_name(const char* value);
  inline void set_name(const char* value, size_t size);
  inline ::std::string* mutable_name();
  inline ::std::string* release_name();
  inline void set_allocated_name(::std::string* name);

  // optional string type = 2;
  inline bool has_type() const;
  inline void clear_type();
  static const int kTypeFieldNumber = 2;
  inline const ::std::string& type() const;
  inline void set_type(const ::std::string& value);
  inline void set_type(const char* value);
  inline void set_type(const char* value, size_t size);
  inline ::std::string* mutable_type();
  inline ::std::string* release_type();
  inline void set_allocated_type(::std::string* type);

  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  inline int layerstruct_size() const;
  inline void clear_layerstruct();
  static const int kLayerStructFieldNumber = 100;
  inline const ::DeepLearning::LayerStructParameter& layerstruct(int index) const;
  inline ::DeepLearning::LayerStructParameter* mutable_layerstruct(int index);
  inline ::DeepLearning::LayerStructParameter* add_layerstruct();
  inline const ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter >&
      layerstruct() const;
  inline ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter >*
      mutable_layerstruct();

  // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
  inline bool has_neuralnettrainingparameter() const;
  inline void clear_neuralnettrainingparameter();
  static const int kNeuralNetTrainingParameterFieldNumber = 101;
  inline const ::DeepLearning::NeuralNetTrainingParameter& neuralnettrainingparameter() const;
  inline ::DeepLearning::NeuralNetTrainingParameter* mutable_neuralnettrainingparameter();
  inline ::DeepLearning::NeuralNetTrainingParameter* release_neuralnettrainingparameter();
  inline void set_allocated_neuralnettrainingparameter(::DeepLearning::NeuralNetTrainingParameter* neuralnettrainingparameter);

  // @@protoc_insertion_point(class_scope:DeepLearning.NeuralNetParameter)
 private:
  inline void set_has_name();
  inline void clear_has_name();
  inline void set_has_type();
  inline void clear_has_type();
  inline void set_has_neuralnettrainingparameter();
  inline void clear_has_neuralnettrainingparameter();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  ::std::string* name_;
  ::std::string* type_;
  ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter > layerstruct_;
  ::DeepLearning::NeuralNetTrainingParameter* neuralnettrainingparameter_;
  friend void  protobuf_AddDesc_DeepLearning_2eproto();
  friend void protobuf_AssignDesc_DeepLearning_2eproto();
  friend void protobuf_ShutdownFile_DeepLearning_2eproto();

  void InitAsDefaultInstance();
  static NeuralNetParameter* default_instance_;
};
// -------------------------------------------------------------------

class LayerStructParameter : public ::google::protobuf::Message {
 public:
  LayerStructParameter();
  virtual ~LayerStructParameter();

  LayerStructParameter(const LayerStructParameter& from);

  inline LayerStructParameter& operator=(const LayerStructParameter& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const LayerStructParameter& default_instance();

  void Swap(LayerStructParameter* other);

  // implements Message ----------------------------------------------

  LayerStructParameter* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const LayerStructParameter& from);
  void MergeFrom(const LayerStructParameter& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  typedef LayerStructParameter_ActivationType ActivationType;
  static const ActivationType sigmoid = LayerStructParameter_ActivationType_sigmoid;
  static const ActivationType tanh = LayerStructParameter_ActivationType_tanh;
  static const ActivationType linear = LayerStructParameter_ActivationType_linear;
  static const ActivationType softmax = LayerStructParameter_ActivationType_softmax;
  static inline bool ActivationType_IsValid(int value) {
    return LayerStructParameter_ActivationType_IsValid(value);
  }
  static const ActivationType ActivationType_MIN =
    LayerStructParameter_ActivationType_ActivationType_MIN;
  static const ActivationType ActivationType_MAX =
    LayerStructParameter_ActivationType_ActivationType_MAX;
  static const int ActivationType_ARRAYSIZE =
    LayerStructParameter_ActivationType_ActivationType_ARRAYSIZE;
  static inline const ::google::protobuf::EnumDescriptor*
  ActivationType_descriptor() {
    return LayerStructParameter_ActivationType_descriptor();
  }
  static inline const ::std::string& ActivationType_Name(ActivationType value) {
    return LayerStructParameter_ActivationType_Name(value);
  }
  static inline bool ActivationType_Parse(const ::std::string& name,
      ActivationType* value) {
    return LayerStructParameter_ActivationType_Parse(name, value);
  }

  // accessors -------------------------------------------------------

  // optional int32 inputDim = 1;
  inline bool has_inputdim() const;
  inline void clear_inputdim();
  static const int kInputDimFieldNumber = 1;
  inline ::google::protobuf::int32 inputdim() const;
  inline void set_inputdim(::google::protobuf::int32 value);

  // optional int32 outputDim = 2;
  inline bool has_outputdim() const;
  inline void clear_outputdim();
  static const int kOutputDimFieldNumber = 2;
  inline ::google::protobuf::int32 outputdim() const;
  inline void set_outputdim(::google::protobuf::int32 value);

  // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
  inline bool has_activationtype() const;
  inline void clear_activationtype();
  static const int kActivationTypeFieldNumber = 3;
  inline ::DeepLearning::LayerStructParameter_ActivationType activationtype() const;
  inline void set_activationtype(::DeepLearning::LayerStructParameter_ActivationType value);

  // optional string name = 4;
  inline bool has_name() const;
  inline void clear_name();
  static const int kNameFieldNumber = 4;
  inline const ::std::string& name() const;
  inline void set_name(const ::std::string& value);
  inline void set_name(const char* value);
  inline void set_name(const char* value, size_t size);
  inline ::std::string* mutable_name();
  inline ::std::string* release_name();
  inline void set_allocated_name(::std::string* name);

  // optional string type = 5;
  inline bool has_type() const;
  inline void clear_type();
  static const int kTypeFieldNumber = 5;
  inline const ::std::string& type() const;
  inline void set_type(const ::std::string& value);
  inline void set_type(const char* value);
  inline void set_type(const char* value, size_t size);
  inline ::std::string* mutable_type();
  inline ::std::string* release_type();
  inline void set_allocated_type(::std::string* type);

  // @@protoc_insertion_point(class_scope:DeepLearning.LayerStructParameter)
 private:
  inline void set_has_inputdim();
  inline void clear_has_inputdim();
  inline void set_has_outputdim();
  inline void clear_has_outputdim();
  inline void set_has_activationtype();
  inline void clear_has_activationtype();
  inline void set_has_name();
  inline void clear_has_name();
  inline void set_has_type();
  inline void clear_has_type();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  ::google::protobuf::int32 inputdim_;
  ::google::protobuf::int32 outputdim_;
  ::std::string* name_;
  ::std::string* type_;
  int activationtype_;
  friend void  protobuf_AddDesc_DeepLearning_2eproto();
  friend void protobuf_AssignDesc_DeepLearning_2eproto();
  friend void protobuf_ShutdownFile_DeepLearning_2eproto();

  void InitAsDefaultInstance();
  static LayerStructParameter* default_instance_;
};
// -------------------------------------------------------------------

class NeuralNetTrainingParameter : public ::google::protobuf::Message {
 public:
  NeuralNetTrainingParameter();
  virtual ~NeuralNetTrainingParameter();

  NeuralNetTrainingParameter(const NeuralNetTrainingParameter& from);

  inline NeuralNetTrainingParameter& operator=(const NeuralNetTrainingParameter& from) {
    CopyFrom(from);
    return *this;
  }

  inline const ::google::protobuf::UnknownFieldSet& unknown_fields() const {
    return _unknown_fields_;
  }

  inline ::google::protobuf::UnknownFieldSet* mutable_unknown_fields() {
    return &_unknown_fields_;
  }

  static const ::google::protobuf::Descriptor* descriptor();
  static const NeuralNetTrainingParameter& default_instance();

  void Swap(NeuralNetTrainingParameter* other);

  // implements Message ----------------------------------------------

  NeuralNetTrainingParameter* New() const;
  void CopyFrom(const ::google::protobuf::Message& from);
  void MergeFrom(const ::google::protobuf::Message& from);
  void CopyFrom(const NeuralNetTrainingParameter& from);
  void MergeFrom(const NeuralNetTrainingParameter& from);
  void Clear();
  bool IsInitialized() const;

  int ByteSize() const;
  bool MergePartialFromCodedStream(
      ::google::protobuf::io::CodedInputStream* input);
  void SerializeWithCachedSizes(
      ::google::protobuf::io::CodedOutputStream* output) const;
  ::google::protobuf::uint8* SerializeWithCachedSizesToArray(::google::protobuf::uint8* output) const;
  int GetCachedSize() const { return _cached_size_; }
  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  public:
  ::google::protobuf::Metadata GetMetadata() const;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  // optional double learningRate = 1;
  inline bool has_learningrate() const;
  inline void clear_learningrate();
  static const int kLearningRateFieldNumber = 1;
  inline double learningrate() const;
  inline void set_learningrate(double value);

  // optional int32 maxIter = 2;
  inline bool has_maxiter() const;
  inline void clear_maxiter();
  static const int kMaxIterFieldNumber = 2;
  inline ::google::protobuf::int32 maxiter() const;
  inline void set_maxiter(::google::protobuf::int32 value);

  // optional int32 miniBatchSize = 3;
  inline bool has_minibatchsize() const;
  inline void clear_minibatchsize();
  static const int kMiniBatchSizeFieldNumber = 3;
  inline ::google::protobuf::int32 minibatchsize() const;
  inline void set_minibatchsize(::google::protobuf::int32 value);

  // optional int32 NEpoch = 4;
  inline bool has_nepoch() const;
  inline void clear_nepoch();
  static const int kNEpochFieldNumber = 4;
  inline ::google::protobuf::int32 nepoch() const;
  inline void set_nepoch(::google::protobuf::int32 value);

  // optional double epi = 5 [default = 1e-06];
  inline bool has_epi() const;
  inline void clear_epi();
  static const int kEpiFieldNumber = 5;
  inline double epi() const;
  inline void set_epi(double value);

  // @@protoc_insertion_point(class_scope:DeepLearning.NeuralNetTrainingParameter)
 private:
  inline void set_has_learningrate();
  inline void clear_has_learningrate();
  inline void set_has_maxiter();
  inline void clear_has_maxiter();
  inline void set_has_minibatchsize();
  inline void clear_has_minibatchsize();
  inline void set_has_nepoch();
  inline void clear_has_nepoch();
  inline void set_has_epi();
  inline void clear_has_epi();

  ::google::protobuf::UnknownFieldSet _unknown_fields_;

  ::google::protobuf::uint32 _has_bits_[1];
  mutable int _cached_size_;
  double learningrate_;
  ::google::protobuf::int32 maxiter_;
  ::google::protobuf::int32 minibatchsize_;
  double epi_;
  ::google::protobuf::int32 nepoch_;
  friend void  protobuf_AddDesc_DeepLearning_2eproto();
  friend void protobuf_AssignDesc_DeepLearning_2eproto();
  friend void protobuf_ShutdownFile_DeepLearning_2eproto();

  void InitAsDefaultInstance();
  static NeuralNetTrainingParameter* default_instance_;
};
// ===================================================================


// ===================================================================

// NeuralNetParameter

// optional string name = 1;
inline bool NeuralNetParameter::has_name() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NeuralNetParameter::set_has_name() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NeuralNetParameter::clear_has_name() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NeuralNetParameter::clear_name() {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_->clear();
  }
  clear_has_name();
}
inline const ::std::string& NeuralNetParameter::name() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.name)
  return *name_;
}
inline void NeuralNetParameter::set_name(const ::std::string& value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetParameter.name)
}
inline void NeuralNetParameter::set_name(const char* value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set_char:DeepLearning.NeuralNetParameter.name)
}
inline void NeuralNetParameter::set_name(const char* value, size_t size) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.NeuralNetParameter.name)
}
inline ::std::string* NeuralNetParameter::mutable_name() {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.name)
  return name_;
}
inline ::std::string* NeuralNetParameter::release_name() {
  clear_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = name_;
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void NeuralNetParameter::set_allocated_name(::std::string* name) {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete name_;
  }
  if (name) {
    set_has_name();
    name_ = name;
  } else {
    clear_has_name();
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.name)
}

// optional string type = 2;
inline bool NeuralNetParameter::has_type() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NeuralNetParameter::set_has_type() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NeuralNetParameter::clear_has_type() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NeuralNetParameter::clear_type() {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_->clear();
  }
  clear_has_type();
}
inline const ::std::string& NeuralNetParameter::type() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.type)
  return *type_;
}
inline void NeuralNetParameter::set_type(const ::std::string& value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetParameter.type)
}
inline void NeuralNetParameter::set_type(const char* value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set_char:DeepLearning.NeuralNetParameter.type)
}
inline void NeuralNetParameter::set_type(const char* value, size_t size) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.NeuralNetParameter.type)
}
inline ::std::string* NeuralNetParameter::mutable_type() {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.type)
  return type_;
}
inline ::std::string* NeuralNetParameter::release_type() {
  clear_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = type_;
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void NeuralNetParameter::set_allocated_type(::std::string* type) {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete type_;
  }
  if (type) {
    set_has_type();
    type_ = type;
  } else {
    clear_has_type();
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.type)
}

// repeated .DeepLearning.LayerStructParameter layerStruct = 100;
inline int NeuralNetParameter::layerstruct_size() const {
  return layerstruct_.size();
}
inline void NeuralNetParameter::clear_layerstruct() {
  layerstruct_.Clear();
}
inline const ::DeepLearning::LayerStructParameter& NeuralNetParameter::layerstruct(int index) const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_.Get(index);
}
inline ::DeepLearning::LayerStructParameter* NeuralNetParameter::mutable_layerstruct(int index) {
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_.Mutable(index);
}
inline ::DeepLearning::LayerStructParameter* NeuralNetParameter::add_layerstruct() {
  // @@protoc_insertion_point(field_add:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_.Add();
}
inline const ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter >&
NeuralNetParameter::layerstruct() const {
  // @@protoc_insertion_point(field_list:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_;
}
inline ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter >*
NeuralNetParameter::mutable_layerstruct() {
  // @@protoc_insertion_point(field_mutable_list:DeepLearning.NeuralNetParameter.layerStruct)
  return &layerstruct_;
}

// optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
inline bool NeuralNetParameter::has_neuralnettrainingparameter() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void NeuralNetParameter::set_has_neuralnettrainingparameter() {
  _has_bits_[0] |= 0x00000008u;
}
inline void NeuralNetParameter::clear_has_neuralnettrainingparameter() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void NeuralNetParameter::clear_neuralnettrainingparameter() {
  if (neuralnettrainingparameter_ != NULL) neuralnettrainingparameter_->::DeepLearning::NeuralNetTrainingParameter::Clear();
  clear_has_neuralnettrainingparameter();
}
inline const ::DeepLearning::NeuralNetTrainingParameter& NeuralNetParameter::neuralnettrainingparameter() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.neuralNetTrainingParameter)
  return neuralnettrainingparameter_ != NULL ? *neuralnettrainingparameter_ : *default_instance_->neuralnettrainingparameter_;
}
inline ::DeepLearning::NeuralNetTrainingParameter* NeuralNetParameter::mutable_neuralnettrainingparameter() {
  set_has_neuralnettrainingparameter();
  if (neuralnettrainingparameter_ == NULL) neuralnettrainingparameter_ = new ::DeepLearning::NeuralNetTrainingParameter;
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.neuralNetTrainingParameter)
  return neuralnettrainingparameter_;
}
inline ::DeepLearning::NeuralNetTrainingParameter* NeuralNetParameter::release_neuralnettrainingparameter() {
  clear_has_neuralnettrainingparameter();
  ::DeepLearning::NeuralNetTrainingParameter* temp = neuralnettrainingparameter_;
  neuralnettrainingparameter_ = NULL;
  return temp;
}
inline void NeuralNetParameter::set_allocated_neuralnettrainingparameter(::DeepLearning::NeuralNetTrainingParameter* neuralnettrainingparameter) {
  delete neuralnettrainingparameter_;
  neuralnettrainingparameter_ = neuralnettrainingparameter;
  if (neuralnettrainingparameter) {
    set_has_neuralnettrainingparameter();
  } else {
    clear_has_neuralnettrainingparameter();
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.neuralNetTrainingParameter)
}

// -------------------------------------------------------------------

// LayerStructParameter

// optional int32 inputDim = 1;
inline bool LayerStructParameter::has_inputdim() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void LayerStructParameter::set_has_inputdim() {
  _has_bits_[0] |= 0x00000001u;
}
inline void LayerStructParameter::clear_has_inputdim() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void LayerStructParameter::clear_inputdim() {
  inputdim_ = 0;
  clear_has_inputdim();
}
inline ::google::protobuf::int32 LayerStructParameter::inputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.inputDim)
  return inputdim_;
}
inline void LayerStructParameter::set_inputdim(::google::protobuf::int32 value) {
  set_has_inputdim();
  inputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.inputDim)
}

// optional int32 outputDim = 2;
inline bool LayerStructParameter::has_outputdim() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void LayerStructParameter::set_has_outputdim() {
  _has_bits_[0] |= 0x00000002u;
}
inline void LayerStructParameter::clear_has_outputdim() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void LayerStructParameter::clear_outputdim() {
  outputdim_ = 0;
  clear_has_outputdim();
}
inline ::google::protobuf::int32 LayerStructParameter::outputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.outputDim)
  return outputdim_;
}
inline void LayerStructParameter::set_outputdim(::google::protobuf::int32 value) {
  set_has_outputdim();
  outputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.outputDim)
}

// optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
inline bool LayerStructParameter::has_activationtype() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void LayerStructParameter::set_has_activationtype() {
  _has_bits_[0] |= 0x00000004u;
}
inline void LayerStructParameter::clear_has_activationtype() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void LayerStructParameter::clear_activationtype() {
  activationtype_ = 1;
  clear_has_activationtype();
}
inline ::DeepLearning::LayerStructParameter_ActivationType LayerStructParameter::activationtype() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.activationType)
  return static_cast< ::DeepLearning::LayerStructParameter_ActivationType >(activationtype_);
}
inline void LayerStructParameter::set_activationtype(::DeepLearning::LayerStructParameter_ActivationType value) {
  assert(::DeepLearning::LayerStructParameter_ActivationType_IsValid(value));
  set_has_activationtype();
  activationtype_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.activationType)
}

// optional string name = 4;
inline bool LayerStructParameter::has_name() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void LayerStructParameter::set_has_name() {
  _has_bits_[0] |= 0x00000008u;
}
inline void LayerStructParameter::clear_has_name() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void LayerStructParameter::clear_name() {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_->clear();
  }
  clear_has_name();
}
inline const ::std::string& LayerStructParameter::name() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.name)
  return *name_;
}
inline void LayerStructParameter::set_name(const ::std::string& value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.name)
}
inline void LayerStructParameter::set_name(const char* value) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(value);
  // @@protoc_insertion_point(field_set_char:DeepLearning.LayerStructParameter.name)
}
inline void LayerStructParameter::set_name(const char* value, size_t size) {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  name_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.LayerStructParameter.name)
}
inline ::std::string* LayerStructParameter::mutable_name() {
  set_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    name_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:DeepLearning.LayerStructParameter.name)
  return name_;
}
inline ::std::string* LayerStructParameter::release_name() {
  clear_has_name();
  if (name_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = name_;
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void LayerStructParameter::set_allocated_name(::std::string* name) {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete name_;
  }
  if (name) {
    set_has_name();
    name_ = name;
  } else {
    clear_has_name();
    name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.LayerStructParameter.name)
}

// optional string type = 5;
inline bool LayerStructParameter::has_type() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void LayerStructParameter::set_has_type() {
  _has_bits_[0] |= 0x00000010u;
}
inline void LayerStructParameter::clear_has_type() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void LayerStructParameter::clear_type() {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_->clear();
  }
  clear_has_type();
}
inline const ::std::string& LayerStructParameter::type() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.type)
  return *type_;
}
inline void LayerStructParameter::set_type(const ::std::string& value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.type)
}
inline void LayerStructParameter::set_type(const char* value) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(value);
  // @@protoc_insertion_point(field_set_char:DeepLearning.LayerStructParameter.type)
}
inline void LayerStructParameter::set_type(const char* value, size_t size) {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  type_->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.LayerStructParameter.type)
}
inline ::std::string* LayerStructParameter::mutable_type() {
  set_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    type_ = new ::std::string;
  }
  // @@protoc_insertion_point(field_mutable:DeepLearning.LayerStructParameter.type)
  return type_;
}
inline ::std::string* LayerStructParameter::release_type() {
  clear_has_type();
  if (type_ == &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    return NULL;
  } else {
    ::std::string* temp = type_;
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    return temp;
  }
}
inline void LayerStructParameter::set_allocated_type(::std::string* type) {
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete type_;
  }
  if (type) {
    set_has_type();
    type_ = type;
  } else {
    clear_has_type();
    type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.LayerStructParameter.type)
}

// -------------------------------------------------------------------

// NeuralNetTrainingParameter

// optional double learningRate = 1;
inline bool NeuralNetTrainingParameter::has_learningrate() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
inline void NeuralNetTrainingParameter::set_has_learningrate() {
  _has_bits_[0] |= 0x00000001u;
}
inline void NeuralNetTrainingParameter::clear_has_learningrate() {
  _has_bits_[0] &= ~0x00000001u;
}
inline void NeuralNetTrainingParameter::clear_learningrate() {
  learningrate_ = 0;
  clear_has_learningrate();
}
inline double NeuralNetTrainingParameter::learningrate() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.learningRate)
  return learningrate_;
}
inline void NeuralNetTrainingParameter::set_learningrate(double value) {
  set_has_learningrate();
  learningrate_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.learningRate)
}

// optional int32 maxIter = 2;
inline bool NeuralNetTrainingParameter::has_maxiter() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
inline void NeuralNetTrainingParameter::set_has_maxiter() {
  _has_bits_[0] |= 0x00000002u;
}
inline void NeuralNetTrainingParameter::clear_has_maxiter() {
  _has_bits_[0] &= ~0x00000002u;
}
inline void NeuralNetTrainingParameter::clear_maxiter() {
  maxiter_ = 0;
  clear_has_maxiter();
}
inline ::google::protobuf::int32 NeuralNetTrainingParameter::maxiter() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.maxIter)
  return maxiter_;
}
inline void NeuralNetTrainingParameter::set_maxiter(::google::protobuf::int32 value) {
  set_has_maxiter();
  maxiter_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.maxIter)
}

// optional int32 miniBatchSize = 3;
inline bool NeuralNetTrainingParameter::has_minibatchsize() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
inline void NeuralNetTrainingParameter::set_has_minibatchsize() {
  _has_bits_[0] |= 0x00000004u;
}
inline void NeuralNetTrainingParameter::clear_has_minibatchsize() {
  _has_bits_[0] &= ~0x00000004u;
}
inline void NeuralNetTrainingParameter::clear_minibatchsize() {
  minibatchsize_ = 0;
  clear_has_minibatchsize();
}
inline ::google::protobuf::int32 NeuralNetTrainingParameter::minibatchsize() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.miniBatchSize)
  return minibatchsize_;
}
inline void NeuralNetTrainingParameter::set_minibatchsize(::google::protobuf::int32 value) {
  set_has_minibatchsize();
  minibatchsize_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.miniBatchSize)
}

// optional int32 NEpoch = 4;
inline bool NeuralNetTrainingParameter::has_nepoch() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
inline void NeuralNetTrainingParameter::set_has_nepoch() {
  _has_bits_[0] |= 0x00000008u;
}
inline void NeuralNetTrainingParameter::clear_has_nepoch() {
  _has_bits_[0] &= ~0x00000008u;
}
inline void NeuralNetTrainingParameter::clear_nepoch() {
  nepoch_ = 0;
  clear_has_nepoch();
}
inline ::google::protobuf::int32 NeuralNetTrainingParameter::nepoch() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.NEpoch)
  return nepoch_;
}
inline void NeuralNetTrainingParameter::set_nepoch(::google::protobuf::int32 value) {
  set_has_nepoch();
  nepoch_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.NEpoch)
}

// optional double epi = 5 [default = 1e-06];
inline bool NeuralNetTrainingParameter::has_epi() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
inline void NeuralNetTrainingParameter::set_has_epi() {
  _has_bits_[0] |= 0x00000010u;
}
inline void NeuralNetTrainingParameter::clear_has_epi() {
  _has_bits_[0] &= ~0x00000010u;
}
inline void NeuralNetTrainingParameter::clear_epi() {
  epi_ = 1e-06;
  clear_has_epi();
}
inline double NeuralNetTrainingParameter::epi() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.epi)
  return epi_;
}
inline void NeuralNetTrainingParameter::set_epi(double value) {
  set_has_epi();
  epi_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.epi)
}


// @@protoc_insertion_point(namespace_scope)

}  // namespace DeepLearning

#ifndef SWIG
namespace google {
namespace protobuf {

template <> struct is_proto_enum< ::DeepLearning::LayerStructParameter_ActivationType> : ::google::protobuf::internal::true_type {};
template <>
inline const EnumDescriptor* GetEnumDescriptor< ::DeepLearning::LayerStructParameter_ActivationType>() {
  return ::DeepLearning::LayerStructParameter_ActivationType_descriptor();
}

}  // namespace google
}  // namespace protobuf
#endif  // SWIG

// @@protoc_insertion_point(global_scope)

#endif  // PROTOBUF_DeepLearning_2eproto__INCLUDED
