// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: DeepLearning.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "DeepLearning.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace DeepLearning {

namespace {

const ::google::protobuf::Descriptor* NeuralNetParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  NeuralNetParameter_reflection_ = NULL;
const ::google::protobuf::Descriptor* LayerStructParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  LayerStructParameter_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* LayerStructParameter_ActivationType_descriptor_ = NULL;
const ::google::protobuf::Descriptor* RNNStructParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RNNStructParameter_reflection_ = NULL;
const ::google::protobuf::Descriptor* NeuralNetTrainingParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  NeuralNetTrainingParameter_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* NeuralNetTrainingParameter_TrainerType_descriptor_ = NULL;

}  // namespace


void protobuf_AssignDesc_DeepLearning_2eproto() {
  protobuf_AddDesc_DeepLearning_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "DeepLearning.proto");
  GOOGLE_CHECK(file != NULL);
  NeuralNetParameter_descriptor_ = file->message_type(0);
  static const int NeuralNetParameter_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, type_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, layerstruct_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, neuralnettrainingparameter_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, rnnstruct_),
  };
  NeuralNetParameter_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      NeuralNetParameter_descriptor_,
      NeuralNetParameter::default_instance_,
      NeuralNetParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, _has_bits_[0]),
      -1,
      -1,
      sizeof(NeuralNetParameter),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, _internal_metadata_),
      -1);
  LayerStructParameter_descriptor_ = file->message_type(1);
  static const int LayerStructParameter_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, inputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, outputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, activationtype_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, type_),
  };
  LayerStructParameter_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      LayerStructParameter_descriptor_,
      LayerStructParameter::default_instance_,
      LayerStructParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, _has_bits_[0]),
      -1,
      -1,
      sizeof(LayerStructParameter),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, _internal_metadata_),
      -1);
  LayerStructParameter_ActivationType_descriptor_ = LayerStructParameter_descriptor_->enum_type(0);
  RNNStructParameter_descriptor_ = file->message_type(2);
  static const int RNNStructParameter_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, numhiddenlayers_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, hiddenlayerinputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, hiddenlayeroutputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, inputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, outputdim_),
  };
  RNNStructParameter_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      RNNStructParameter_descriptor_,
      RNNStructParameter::default_instance_,
      RNNStructParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, _has_bits_[0]),
      -1,
      -1,
      sizeof(RNNStructParameter),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, _internal_metadata_),
      -1);
  NeuralNetTrainingParameter_descriptor_ = file->message_type(3);
  static const int NeuralNetTrainingParameter_offsets_[10] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, learningrate_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, maxiter_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, minibatchsize_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, nepoch_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, epi_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, trainertype_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, decayrate_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, momentum_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, verbose_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, printinfofrequency_),
  };
  NeuralNetTrainingParameter_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      NeuralNetTrainingParameter_descriptor_,
      NeuralNetTrainingParameter::default_instance_,
      NeuralNetTrainingParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, _has_bits_[0]),
      -1,
      -1,
      sizeof(NeuralNetTrainingParameter),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, _internal_metadata_),
      -1);
  NeuralNetTrainingParameter_TrainerType_descriptor_ = NeuralNetTrainingParameter_descriptor_->enum_type(0);
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_DeepLearning_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      NeuralNetParameter_descriptor_, &NeuralNetParameter::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      LayerStructParameter_descriptor_, &LayerStructParameter::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      RNNStructParameter_descriptor_, &RNNStructParameter::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      NeuralNetTrainingParameter_descriptor_, &NeuralNetTrainingParameter::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_DeepLearning_2eproto() {
  delete NeuralNetParameter::default_instance_;
  delete NeuralNetParameter_reflection_;
  delete LayerStructParameter::default_instance_;
  delete LayerStructParameter_reflection_;
  delete RNNStructParameter::default_instance_;
  delete RNNStructParameter_reflection_;
  delete NeuralNetTrainingParameter::default_instance_;
  delete NeuralNetTrainingParameter_reflection_;
}

void protobuf_AddDesc_DeepLearning_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n\022DeepLearning.proto\022\014DeepLearning\"\354\001\n\022N"
    "euralNetParameter\022\014\n\004name\030\001 \001(\t\022\014\n\004type\030"
    "\002 \001(\t\0227\n\013layerStruct\030d \003(\0132\".DeepLearnin"
    "g.LayerStructParameter\022L\n\032neuralNetTrain"
    "ingParameter\030e \001(\0132(.DeepLearning.Neural"
    "NetTrainingParameter\0223\n\trnnStruct\030f \001(\0132"
    " .DeepLearning.RNNStructParameter\"\344\001\n\024La"
    "yerStructParameter\022\020\n\010inputDim\030\001 \001(\005\022\021\n\t"
    "outputDim\030\002 \001(\005\022I\n\016activationType\030\003 \001(\0162"
    "1.DeepLearning.LayerStructParameter.Acti"
    "vationType\022\014\n\004name\030\004 \001(\t\022\014\n\004type\030\005 \001(\t\"@"
    "\n\016ActivationType\022\013\n\007sigmoid\020\001\022\010\n\004tanh\020\002\022"
    "\n\n\006linear\020\003\022\013\n\007softmax\020\004\"\215\001\n\022RNNStructPa"
    "rameter\022\027\n\017numHiddenLayers\030\001 \001(\005\022\033\n\023hidd"
    "enLayerInputDim\030\002 \001(\005\022\034\n\024hiddenLayerOutp"
    "utDim\030\003 \001(\005\022\020\n\010inputDim\030\004 \001(\005\022\021\n\toutputD"
    "im\030\005 \001(\005\"\326\002\n\032NeuralNetTrainingParameter\022"
    "\024\n\014learningRate\030\001 \001(\001\022\017\n\007maxIter\030\002 \001(\005\022\025"
    "\n\rminiBatchSize\030\003 \001(\005\022\016\n\006NEpoch\030\004 \001(\005\022\022\n"
    "\003epi\030\005 \001(\001:\0051e-06\022N\n\013trainerType\030\006 \001(\01624"
    ".DeepLearning.NeuralNetTrainingParameter"
    ".TrainerType:\003SGD\022\025\n\tdecayRate\030\007 \001(\001:\00210"
    "\022\025\n\010momentum\030\010 \001(\001:\0030.9\022\025\n\007verbose\030\t \001(\010"
    ":\004true\022\035\n\022printInfoFrequency\030\n \001(\005:\0011\"\"\n"
    "\013TrainerType\022\007\n\003SGD\020\001\022\n\n\006iRProp\020\002", 993);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "DeepLearning.proto", &protobuf_RegisterTypes);
  NeuralNetParameter::default_instance_ = new NeuralNetParameter();
  LayerStructParameter::default_instance_ = new LayerStructParameter();
  RNNStructParameter::default_instance_ = new RNNStructParameter();
  NeuralNetTrainingParameter::default_instance_ = new NeuralNetTrainingParameter();
  NeuralNetParameter::default_instance_->InitAsDefaultInstance();
  LayerStructParameter::default_instance_->InitAsDefaultInstance();
  RNNStructParameter::default_instance_->InitAsDefaultInstance();
  NeuralNetTrainingParameter::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_DeepLearning_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_DeepLearning_2eproto {
  StaticDescriptorInitializer_DeepLearning_2eproto() {
    protobuf_AddDesc_DeepLearning_2eproto();
  }
} static_descriptor_initializer_DeepLearning_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD;
static void MergeFromFail(int line) {
  GOOGLE_CHECK(false) << __FILE__ << ":" << line;
}

}  // namespace


// ===================================================================

#ifndef _MSC_VER
const int NeuralNetParameter::kNameFieldNumber;
const int NeuralNetParameter::kTypeFieldNumber;
const int NeuralNetParameter::kLayerStructFieldNumber;
const int NeuralNetParameter::kNeuralNetTrainingParameterFieldNumber;
const int NeuralNetParameter::kRnnStructFieldNumber;
#endif  // !_MSC_VER

NeuralNetParameter::NeuralNetParameter()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.NeuralNetParameter)
}

void NeuralNetParameter::InitAsDefaultInstance() {
  neuralnettrainingparameter_ = const_cast< ::DeepLearning::NeuralNetTrainingParameter*>(&::DeepLearning::NeuralNetTrainingParameter::default_instance());
  rnnstruct_ = const_cast< ::DeepLearning::RNNStructParameter*>(&::DeepLearning::RNNStructParameter::default_instance());
}

NeuralNetParameter::NeuralNetParameter(const NeuralNetParameter& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.NeuralNetParameter)
}

void NeuralNetParameter::SharedCtor() {
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  type_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  neuralnettrainingparameter_ = NULL;
  rnnstruct_ = NULL;
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

NeuralNetParameter::~NeuralNetParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.NeuralNetParameter)
  SharedDtor();
}

void NeuralNetParameter::SharedDtor() {
  name_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  type_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
    delete neuralnettrainingparameter_;
    delete rnnstruct_;
  }
}

void NeuralNetParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* NeuralNetParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NeuralNetParameter_descriptor_;
}

const NeuralNetParameter& NeuralNetParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

NeuralNetParameter* NeuralNetParameter::default_instance_ = NULL;

NeuralNetParameter* NeuralNetParameter::New(::google::protobuf::Arena* arena) const {
  NeuralNetParameter* n = new NeuralNetParameter;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void NeuralNetParameter::Clear() {
  if (_has_bits_[0 / 32] & 27u) {
    if (has_name()) {
      name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    }
    if (has_type()) {
      type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    }
    if (has_neuralnettrainingparameter()) {
      if (neuralnettrainingparameter_ != NULL) neuralnettrainingparameter_->::DeepLearning::NeuralNetTrainingParameter::Clear();
    }
    if (has_rnnstruct()) {
      if (rnnstruct_ != NULL) rnnstruct_->::DeepLearning::RNNStructParameter::Clear();
    }
  }
  layerstruct_.Clear();
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  if (_internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->Clear();
  }
}

bool NeuralNetParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.NeuralNetParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(16383);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string name = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "DeepLearning.NeuralNetParameter.name");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_type;
        break;
      }

      // optional string type = 2;
      case 2: {
        if (tag == 18) {
         parse_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_type()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->type().data(), this->type().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "DeepLearning.NeuralNetParameter.type");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(802)) goto parse_layerStruct;
        break;
      }

      // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
      case 100: {
        if (tag == 802) {
         parse_layerStruct:
          DO_(input->IncrementRecursionDepth());
         parse_loop_layerStruct:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_layerstruct()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(802)) goto parse_loop_layerStruct;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectTag(810)) goto parse_neuralNetTrainingParameter;
        break;
      }

      // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
      case 101: {
        if (tag == 810) {
         parse_neuralNetTrainingParameter:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_neuralnettrainingparameter()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(818)) goto parse_rnnStruct;
        break;
      }

      // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
      case 102: {
        if (tag == 818) {
         parse_rnnStruct:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_rnnstruct()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.NeuralNetParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.NeuralNetParameter)
  return false;
#undef DO_
}

void NeuralNetParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.NeuralNetParameter)
  // optional string name = 1;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.NeuralNetParameter.name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->name(), output);
  }

  // optional string type = 2;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.NeuralNetParameter.type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->type(), output);
  }

  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  for (unsigned int i = 0, n = this->layerstruct_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      100, this->layerstruct(i), output);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
  if (has_neuralnettrainingparameter()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      101, *this->neuralnettrainingparameter_, output);
  }

  // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
  if (has_rnnstruct()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      102, *this->rnnstruct_, output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.NeuralNetParameter)
}

::google::protobuf::uint8* NeuralNetParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.NeuralNetParameter)
  // optional string name = 1;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.NeuralNetParameter.name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->name(), target);
  }

  // optional string type = 2;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.NeuralNetParameter.type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->type(), target);
  }

  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  for (unsigned int i = 0, n = this->layerstruct_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        100, this->layerstruct(i), target);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
  if (has_neuralnettrainingparameter()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        101, *this->neuralnettrainingparameter_, target);
  }

  // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
  if (has_rnnstruct()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        102, *this->rnnstruct_, target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.NeuralNetParameter)
  return target;
}

int NeuralNetParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & 27) {
    // optional string name = 1;
    if (has_name()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->name());
    }

    // optional string type = 2;
    if (has_type()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->type());
    }

    // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
    if (has_neuralnettrainingparameter()) {
      total_size += 2 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *this->neuralnettrainingparameter_);
    }

    // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
    if (has_rnnstruct()) {
      total_size += 2 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *this->rnnstruct_);
    }

  }
  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  total_size += 2 * this->layerstruct_size();
  for (int i = 0; i < this->layerstruct_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->layerstruct(i));
  }

  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void NeuralNetParameter::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const NeuralNetParameter* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const NeuralNetParameter>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void NeuralNetParameter::MergeFrom(const NeuralNetParameter& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  layerstruct_.MergeFrom(from.layerstruct_);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_name()) {
      set_has_name();
      name_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.name_);
    }
    if (from.has_type()) {
      set_has_type();
      type_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.type_);
    }
    if (from.has_neuralnettrainingparameter()) {
      mutable_neuralnettrainingparameter()->::DeepLearning::NeuralNetTrainingParameter::MergeFrom(from.neuralnettrainingparameter());
    }
    if (from.has_rnnstruct()) {
      mutable_rnnstruct()->::DeepLearning::RNNStructParameter::MergeFrom(from.rnnstruct());
    }
  }
  if (from._internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->MergeFrom(from.unknown_fields());
  }
}

void NeuralNetParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void NeuralNetParameter::CopyFrom(const NeuralNetParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool NeuralNetParameter::IsInitialized() const {

  return true;
}

void NeuralNetParameter::Swap(NeuralNetParameter* other) {
  if (other == this) return;
  InternalSwap(other);
}
void NeuralNetParameter::InternalSwap(NeuralNetParameter* other) {
  name_.Swap(&other->name_);
  type_.Swap(&other->type_);
  layerstruct_.UnsafeArenaSwap(&other->layerstruct_);
  std::swap(neuralnettrainingparameter_, other->neuralnettrainingparameter_);
  std::swap(rnnstruct_, other->rnnstruct_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata NeuralNetParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = NeuralNetParameter_descriptor_;
  metadata.reflection = NeuralNetParameter_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// NeuralNetParameter

// optional string name = 1;
bool NeuralNetParameter::has_name() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void NeuralNetParameter::set_has_name() {
  _has_bits_[0] |= 0x00000001u;
}
void NeuralNetParameter::clear_has_name() {
  _has_bits_[0] &= ~0x00000001u;
}
void NeuralNetParameter::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_name();
}
 const ::std::string& NeuralNetParameter::name() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.name)
  return name_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void NeuralNetParameter::set_name(const ::std::string& value) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetParameter.name)
}
 void NeuralNetParameter::set_name(const char* value) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:DeepLearning.NeuralNetParameter.name)
}
 void NeuralNetParameter::set_name(const char* value, size_t size) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.NeuralNetParameter.name)
}
 ::std::string* NeuralNetParameter::mutable_name() {
  set_has_name();
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* NeuralNetParameter::release_name() {
  clear_has_name();
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void NeuralNetParameter::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    set_has_name();
  } else {
    clear_has_name();
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.name)
}

// optional string type = 2;
bool NeuralNetParameter::has_type() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void NeuralNetParameter::set_has_type() {
  _has_bits_[0] |= 0x00000002u;
}
void NeuralNetParameter::clear_has_type() {
  _has_bits_[0] &= ~0x00000002u;
}
void NeuralNetParameter::clear_type() {
  type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_type();
}
 const ::std::string& NeuralNetParameter::type() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.type)
  return type_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void NeuralNetParameter::set_type(const ::std::string& value) {
  set_has_type();
  type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetParameter.type)
}
 void NeuralNetParameter::set_type(const char* value) {
  set_has_type();
  type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:DeepLearning.NeuralNetParameter.type)
}
 void NeuralNetParameter::set_type(const char* value, size_t size) {
  set_has_type();
  type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.NeuralNetParameter.type)
}
 ::std::string* NeuralNetParameter::mutable_type() {
  set_has_type();
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.type)
  return type_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* NeuralNetParameter::release_type() {
  clear_has_type();
  return type_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void NeuralNetParameter::set_allocated_type(::std::string* type) {
  if (type != NULL) {
    set_has_type();
  } else {
    clear_has_type();
  }
  type_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), type);
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.type)
}

// repeated .DeepLearning.LayerStructParameter layerStruct = 100;
int NeuralNetParameter::layerstruct_size() const {
  return layerstruct_.size();
}
void NeuralNetParameter::clear_layerstruct() {
  layerstruct_.Clear();
}
 const ::DeepLearning::LayerStructParameter& NeuralNetParameter::layerstruct(int index) const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_.Get(index);
}
 ::DeepLearning::LayerStructParameter* NeuralNetParameter::mutable_layerstruct(int index) {
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_.Mutable(index);
}
 ::DeepLearning::LayerStructParameter* NeuralNetParameter::add_layerstruct() {
  // @@protoc_insertion_point(field_add:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_.Add();
}
 const ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter >&
NeuralNetParameter::layerstruct() const {
  // @@protoc_insertion_point(field_list:DeepLearning.NeuralNetParameter.layerStruct)
  return layerstruct_;
}
 ::google::protobuf::RepeatedPtrField< ::DeepLearning::LayerStructParameter >*
NeuralNetParameter::mutable_layerstruct() {
  // @@protoc_insertion_point(field_mutable_list:DeepLearning.NeuralNetParameter.layerStruct)
  return &layerstruct_;
}

// optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
bool NeuralNetParameter::has_neuralnettrainingparameter() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
void NeuralNetParameter::set_has_neuralnettrainingparameter() {
  _has_bits_[0] |= 0x00000008u;
}
void NeuralNetParameter::clear_has_neuralnettrainingparameter() {
  _has_bits_[0] &= ~0x00000008u;
}
void NeuralNetParameter::clear_neuralnettrainingparameter() {
  if (neuralnettrainingparameter_ != NULL) neuralnettrainingparameter_->::DeepLearning::NeuralNetTrainingParameter::Clear();
  clear_has_neuralnettrainingparameter();
}
 const ::DeepLearning::NeuralNetTrainingParameter& NeuralNetParameter::neuralnettrainingparameter() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.neuralNetTrainingParameter)
  return neuralnettrainingparameter_ != NULL ? *neuralnettrainingparameter_ : *default_instance_->neuralnettrainingparameter_;
}
 ::DeepLearning::NeuralNetTrainingParameter* NeuralNetParameter::mutable_neuralnettrainingparameter() {
  set_has_neuralnettrainingparameter();
  if (neuralnettrainingparameter_ == NULL) {
    neuralnettrainingparameter_ = new ::DeepLearning::NeuralNetTrainingParameter;
  }
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.neuralNetTrainingParameter)
  return neuralnettrainingparameter_;
}
 ::DeepLearning::NeuralNetTrainingParameter* NeuralNetParameter::release_neuralnettrainingparameter() {
  clear_has_neuralnettrainingparameter();
  ::DeepLearning::NeuralNetTrainingParameter* temp = neuralnettrainingparameter_;
  neuralnettrainingparameter_ = NULL;
  return temp;
}
 void NeuralNetParameter::set_allocated_neuralnettrainingparameter(::DeepLearning::NeuralNetTrainingParameter* neuralnettrainingparameter) {
  delete neuralnettrainingparameter_;
  neuralnettrainingparameter_ = neuralnettrainingparameter;
  if (neuralnettrainingparameter) {
    set_has_neuralnettrainingparameter();
  } else {
    clear_has_neuralnettrainingparameter();
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.neuralNetTrainingParameter)
}

// optional .DeepLearning.RNNStructParameter rnnStruct = 102;
bool NeuralNetParameter::has_rnnstruct() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
void NeuralNetParameter::set_has_rnnstruct() {
  _has_bits_[0] |= 0x00000010u;
}
void NeuralNetParameter::clear_has_rnnstruct() {
  _has_bits_[0] &= ~0x00000010u;
}
void NeuralNetParameter::clear_rnnstruct() {
  if (rnnstruct_ != NULL) rnnstruct_->::DeepLearning::RNNStructParameter::Clear();
  clear_has_rnnstruct();
}
 const ::DeepLearning::RNNStructParameter& NeuralNetParameter::rnnstruct() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetParameter.rnnStruct)
  return rnnstruct_ != NULL ? *rnnstruct_ : *default_instance_->rnnstruct_;
}
 ::DeepLearning::RNNStructParameter* NeuralNetParameter::mutable_rnnstruct() {
  set_has_rnnstruct();
  if (rnnstruct_ == NULL) {
    rnnstruct_ = new ::DeepLearning::RNNStructParameter;
  }
  // @@protoc_insertion_point(field_mutable:DeepLearning.NeuralNetParameter.rnnStruct)
  return rnnstruct_;
}
 ::DeepLearning::RNNStructParameter* NeuralNetParameter::release_rnnstruct() {
  clear_has_rnnstruct();
  ::DeepLearning::RNNStructParameter* temp = rnnstruct_;
  rnnstruct_ = NULL;
  return temp;
}
 void NeuralNetParameter::set_allocated_rnnstruct(::DeepLearning::RNNStructParameter* rnnstruct) {
  delete rnnstruct_;
  rnnstruct_ = rnnstruct;
  if (rnnstruct) {
    set_has_rnnstruct();
  } else {
    clear_has_rnnstruct();
  }
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.NeuralNetParameter.rnnStruct)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

const ::google::protobuf::EnumDescriptor* LayerStructParameter_ActivationType_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LayerStructParameter_ActivationType_descriptor_;
}
bool LayerStructParameter_ActivationType_IsValid(int value) {
  switch(value) {
    case 1:
    case 2:
    case 3:
    case 4:
      return true;
    default:
      return false;
  }
}

#ifndef _MSC_VER
const LayerStructParameter_ActivationType LayerStructParameter::sigmoid;
const LayerStructParameter_ActivationType LayerStructParameter::tanh;
const LayerStructParameter_ActivationType LayerStructParameter::linear;
const LayerStructParameter_ActivationType LayerStructParameter::softmax;
const LayerStructParameter_ActivationType LayerStructParameter::ActivationType_MIN;
const LayerStructParameter_ActivationType LayerStructParameter::ActivationType_MAX;
const int LayerStructParameter::ActivationType_ARRAYSIZE;
#endif  // _MSC_VER
#ifndef _MSC_VER
const int LayerStructParameter::kInputDimFieldNumber;
const int LayerStructParameter::kOutputDimFieldNumber;
const int LayerStructParameter::kActivationTypeFieldNumber;
const int LayerStructParameter::kNameFieldNumber;
const int LayerStructParameter::kTypeFieldNumber;
#endif  // !_MSC_VER

LayerStructParameter::LayerStructParameter()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.LayerStructParameter)
}

void LayerStructParameter::InitAsDefaultInstance() {
}

LayerStructParameter::LayerStructParameter(const LayerStructParameter& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.LayerStructParameter)
}

void LayerStructParameter::SharedCtor() {
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  inputdim_ = 0;
  outputdim_ = 0;
  activationtype_ = 1;
  name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  type_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

LayerStructParameter::~LayerStructParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.LayerStructParameter)
  SharedDtor();
}

void LayerStructParameter::SharedDtor() {
  name_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  type_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != default_instance_) {
  }
}

void LayerStructParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* LayerStructParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LayerStructParameter_descriptor_;
}

const LayerStructParameter& LayerStructParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

LayerStructParameter* LayerStructParameter::default_instance_ = NULL;

LayerStructParameter* LayerStructParameter::New(::google::protobuf::Arena* arena) const {
  LayerStructParameter* n = new LayerStructParameter;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void LayerStructParameter::Clear() {
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<LayerStructParameter*>(16)->f)

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  if (_has_bits_[0 / 32] & 31u) {
    ZR_(inputdim_, outputdim_);
    activationtype_ = 1;
    if (has_name()) {
      name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    }
    if (has_type()) {
      type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
    }
  }

#undef ZR_HELPER_
#undef ZR_

  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  if (_internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->Clear();
  }
}

bool LayerStructParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.LayerStructParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int32 inputDim = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inputdim_)));
          set_has_inputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_outputDim;
        break;
      }

      // optional int32 outputDim = 2;
      case 2: {
        if (tag == 16) {
         parse_outputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &outputdim_)));
          set_has_outputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_activationType;
        break;
      }

      // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
      case 3: {
        if (tag == 24) {
         parse_activationType:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::DeepLearning::LayerStructParameter_ActivationType_IsValid(value)) {
            set_activationtype(static_cast< ::DeepLearning::LayerStructParameter_ActivationType >(value));
          } else {
            mutable_unknown_fields()->AddVarint(3, value);
          }
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_name;
        break;
      }

      // optional string name = 4;
      case 4: {
        if (tag == 34) {
         parse_name:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "DeepLearning.LayerStructParameter.name");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(42)) goto parse_type;
        break;
      }

      // optional string type = 5;
      case 5: {
        if (tag == 42) {
         parse_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_type()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->type().data(), this->type().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "DeepLearning.LayerStructParameter.type");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.LayerStructParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.LayerStructParameter)
  return false;
#undef DO_
}

void LayerStructParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.LayerStructParameter)
  // optional int32 inputDim = 1;
  if (has_inputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->inputdim(), output);
  }

  // optional int32 outputDim = 2;
  if (has_outputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->outputdim(), output);
  }

  // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
  if (has_activationtype()) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->activationtype(), output);
  }

  // optional string name = 4;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.LayerStructParameter.name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      4, this->name(), output);
  }

  // optional string type = 5;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.LayerStructParameter.type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      5, this->type(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.LayerStructParameter)
}

::google::protobuf::uint8* LayerStructParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.LayerStructParameter)
  // optional int32 inputDim = 1;
  if (has_inputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->inputdim(), target);
  }

  // optional int32 outputDim = 2;
  if (has_outputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->outputdim(), target);
  }

  // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
  if (has_activationtype()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->activationtype(), target);
  }

  // optional string name = 4;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.LayerStructParameter.name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        4, this->name(), target);
  }

  // optional string type = 5;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "DeepLearning.LayerStructParameter.type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        5, this->type(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.LayerStructParameter)
  return target;
}

int LayerStructParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & 31) {
    // optional int32 inputDim = 1;
    if (has_inputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->inputdim());
    }

    // optional int32 outputDim = 2;
    if (has_outputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->outputdim());
    }

    // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
    if (has_activationtype()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::EnumSize(this->activationtype());
    }

    // optional string name = 4;
    if (has_name()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->name());
    }

    // optional string type = 5;
    if (has_type()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->type());
    }

  }
  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void LayerStructParameter::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const LayerStructParameter* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const LayerStructParameter>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void LayerStructParameter::MergeFrom(const LayerStructParameter& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_inputdim()) {
      set_inputdim(from.inputdim());
    }
    if (from.has_outputdim()) {
      set_outputdim(from.outputdim());
    }
    if (from.has_activationtype()) {
      set_activationtype(from.activationtype());
    }
    if (from.has_name()) {
      set_has_name();
      name_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.name_);
    }
    if (from.has_type()) {
      set_has_type();
      type_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.type_);
    }
  }
  if (from._internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->MergeFrom(from.unknown_fields());
  }
}

void LayerStructParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void LayerStructParameter::CopyFrom(const LayerStructParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LayerStructParameter::IsInitialized() const {

  return true;
}

void LayerStructParameter::Swap(LayerStructParameter* other) {
  if (other == this) return;
  InternalSwap(other);
}
void LayerStructParameter::InternalSwap(LayerStructParameter* other) {
  std::swap(inputdim_, other->inputdim_);
  std::swap(outputdim_, other->outputdim_);
  std::swap(activationtype_, other->activationtype_);
  name_.Swap(&other->name_);
  type_.Swap(&other->type_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata LayerStructParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = LayerStructParameter_descriptor_;
  metadata.reflection = LayerStructParameter_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// LayerStructParameter

// optional int32 inputDim = 1;
bool LayerStructParameter::has_inputdim() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void LayerStructParameter::set_has_inputdim() {
  _has_bits_[0] |= 0x00000001u;
}
void LayerStructParameter::clear_has_inputdim() {
  _has_bits_[0] &= ~0x00000001u;
}
void LayerStructParameter::clear_inputdim() {
  inputdim_ = 0;
  clear_has_inputdim();
}
 ::google::protobuf::int32 LayerStructParameter::inputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.inputDim)
  return inputdim_;
}
 void LayerStructParameter::set_inputdim(::google::protobuf::int32 value) {
  set_has_inputdim();
  inputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.inputDim)
}

// optional int32 outputDim = 2;
bool LayerStructParameter::has_outputdim() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void LayerStructParameter::set_has_outputdim() {
  _has_bits_[0] |= 0x00000002u;
}
void LayerStructParameter::clear_has_outputdim() {
  _has_bits_[0] &= ~0x00000002u;
}
void LayerStructParameter::clear_outputdim() {
  outputdim_ = 0;
  clear_has_outputdim();
}
 ::google::protobuf::int32 LayerStructParameter::outputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.outputDim)
  return outputdim_;
}
 void LayerStructParameter::set_outputdim(::google::protobuf::int32 value) {
  set_has_outputdim();
  outputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.outputDim)
}

// optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
bool LayerStructParameter::has_activationtype() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
void LayerStructParameter::set_has_activationtype() {
  _has_bits_[0] |= 0x00000004u;
}
void LayerStructParameter::clear_has_activationtype() {
  _has_bits_[0] &= ~0x00000004u;
}
void LayerStructParameter::clear_activationtype() {
  activationtype_ = 1;
  clear_has_activationtype();
}
 ::DeepLearning::LayerStructParameter_ActivationType LayerStructParameter::activationtype() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.activationType)
  return static_cast< ::DeepLearning::LayerStructParameter_ActivationType >(activationtype_);
}
 void LayerStructParameter::set_activationtype(::DeepLearning::LayerStructParameter_ActivationType value) {
  assert(::DeepLearning::LayerStructParameter_ActivationType_IsValid(value));
  set_has_activationtype();
  activationtype_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.activationType)
}

// optional string name = 4;
bool LayerStructParameter::has_name() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
void LayerStructParameter::set_has_name() {
  _has_bits_[0] |= 0x00000008u;
}
void LayerStructParameter::clear_has_name() {
  _has_bits_[0] &= ~0x00000008u;
}
void LayerStructParameter::clear_name() {
  name_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_name();
}
 const ::std::string& LayerStructParameter::name() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.name)
  return name_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void LayerStructParameter::set_name(const ::std::string& value) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.name)
}
 void LayerStructParameter::set_name(const char* value) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:DeepLearning.LayerStructParameter.name)
}
 void LayerStructParameter::set_name(const char* value, size_t size) {
  set_has_name();
  name_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.LayerStructParameter.name)
}
 ::std::string* LayerStructParameter::mutable_name() {
  set_has_name();
  // @@protoc_insertion_point(field_mutable:DeepLearning.LayerStructParameter.name)
  return name_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* LayerStructParameter::release_name() {
  clear_has_name();
  return name_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void LayerStructParameter::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    set_has_name();
  } else {
    clear_has_name();
  }
  name_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name);
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.LayerStructParameter.name)
}

// optional string type = 5;
bool LayerStructParameter::has_type() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
void LayerStructParameter::set_has_type() {
  _has_bits_[0] |= 0x00000010u;
}
void LayerStructParameter::clear_has_type() {
  _has_bits_[0] &= ~0x00000010u;
}
void LayerStructParameter::clear_type() {
  type_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  clear_has_type();
}
 const ::std::string& LayerStructParameter::type() const {
  // @@protoc_insertion_point(field_get:DeepLearning.LayerStructParameter.type)
  return type_.GetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void LayerStructParameter::set_type(const ::std::string& value) {
  set_has_type();
  type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:DeepLearning.LayerStructParameter.type)
}
 void LayerStructParameter::set_type(const char* value) {
  set_has_type();
  type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:DeepLearning.LayerStructParameter.type)
}
 void LayerStructParameter::set_type(const char* value, size_t size) {
  set_has_type();
  type_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:DeepLearning.LayerStructParameter.type)
}
 ::std::string* LayerStructParameter::mutable_type() {
  set_has_type();
  // @@protoc_insertion_point(field_mutable:DeepLearning.LayerStructParameter.type)
  return type_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 ::std::string* LayerStructParameter::release_type() {
  clear_has_type();
  return type_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
 void LayerStructParameter::set_allocated_type(::std::string* type) {
  if (type != NULL) {
    set_has_type();
  } else {
    clear_has_type();
  }
  type_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), type);
  // @@protoc_insertion_point(field_set_allocated:DeepLearning.LayerStructParameter.type)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#ifndef _MSC_VER
const int RNNStructParameter::kNumHiddenLayersFieldNumber;
const int RNNStructParameter::kHiddenLayerInputDimFieldNumber;
const int RNNStructParameter::kHiddenLayerOutputDimFieldNumber;
const int RNNStructParameter::kInputDimFieldNumber;
const int RNNStructParameter::kOutputDimFieldNumber;
#endif  // !_MSC_VER

RNNStructParameter::RNNStructParameter()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.RNNStructParameter)
}

void RNNStructParameter::InitAsDefaultInstance() {
}

RNNStructParameter::RNNStructParameter(const RNNStructParameter& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.RNNStructParameter)
}

void RNNStructParameter::SharedCtor() {
  _cached_size_ = 0;
  numhiddenlayers_ = 0;
  hiddenlayerinputdim_ = 0;
  hiddenlayeroutputdim_ = 0;
  inputdim_ = 0;
  outputdim_ = 0;
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

RNNStructParameter::~RNNStructParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.RNNStructParameter)
  SharedDtor();
}

void RNNStructParameter::SharedDtor() {
  if (this != default_instance_) {
  }
}

void RNNStructParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RNNStructParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RNNStructParameter_descriptor_;
}

const RNNStructParameter& RNNStructParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

RNNStructParameter* RNNStructParameter::default_instance_ = NULL;

RNNStructParameter* RNNStructParameter::New(::google::protobuf::Arena* arena) const {
  RNNStructParameter* n = new RNNStructParameter;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void RNNStructParameter::Clear() {
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<RNNStructParameter*>(16)->f)

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  if (_has_bits_[0 / 32] & 31u) {
    ZR_(numhiddenlayers_, outputdim_);
  }

#undef ZR_HELPER_
#undef ZR_

  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  if (_internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->Clear();
  }
}

bool RNNStructParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.RNNStructParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int32 numHiddenLayers = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &numhiddenlayers_)));
          set_has_numhiddenlayers();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_hiddenLayerInputDim;
        break;
      }

      // optional int32 hiddenLayerInputDim = 2;
      case 2: {
        if (tag == 16) {
         parse_hiddenLayerInputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &hiddenlayerinputdim_)));
          set_has_hiddenlayerinputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_hiddenLayerOutputDim;
        break;
      }

      // optional int32 hiddenLayerOutputDim = 3;
      case 3: {
        if (tag == 24) {
         parse_hiddenLayerOutputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &hiddenlayeroutputdim_)));
          set_has_hiddenlayeroutputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_inputDim;
        break;
      }

      // optional int32 inputDim = 4;
      case 4: {
        if (tag == 32) {
         parse_inputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inputdim_)));
          set_has_inputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(40)) goto parse_outputDim;
        break;
      }

      // optional int32 outputDim = 5;
      case 5: {
        if (tag == 40) {
         parse_outputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &outputdim_)));
          set_has_outputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.RNNStructParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.RNNStructParameter)
  return false;
#undef DO_
}

void RNNStructParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.RNNStructParameter)
  // optional int32 numHiddenLayers = 1;
  if (has_numhiddenlayers()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->numhiddenlayers(), output);
  }

  // optional int32 hiddenLayerInputDim = 2;
  if (has_hiddenlayerinputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->hiddenlayerinputdim(), output);
  }

  // optional int32 hiddenLayerOutputDim = 3;
  if (has_hiddenlayeroutputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->hiddenlayeroutputdim(), output);
  }

  // optional int32 inputDim = 4;
  if (has_inputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(4, this->inputdim(), output);
  }

  // optional int32 outputDim = 5;
  if (has_outputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(5, this->outputdim(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.RNNStructParameter)
}

::google::protobuf::uint8* RNNStructParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.RNNStructParameter)
  // optional int32 numHiddenLayers = 1;
  if (has_numhiddenlayers()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->numhiddenlayers(), target);
  }

  // optional int32 hiddenLayerInputDim = 2;
  if (has_hiddenlayerinputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->hiddenlayerinputdim(), target);
  }

  // optional int32 hiddenLayerOutputDim = 3;
  if (has_hiddenlayeroutputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->hiddenlayeroutputdim(), target);
  }

  // optional int32 inputDim = 4;
  if (has_inputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(4, this->inputdim(), target);
  }

  // optional int32 outputDim = 5;
  if (has_outputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(5, this->outputdim(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.RNNStructParameter)
  return target;
}

int RNNStructParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & 31) {
    // optional int32 numHiddenLayers = 1;
    if (has_numhiddenlayers()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->numhiddenlayers());
    }

    // optional int32 hiddenLayerInputDim = 2;
    if (has_hiddenlayerinputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->hiddenlayerinputdim());
    }

    // optional int32 hiddenLayerOutputDim = 3;
    if (has_hiddenlayeroutputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->hiddenlayeroutputdim());
    }

    // optional int32 inputDim = 4;
    if (has_inputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->inputdim());
    }

    // optional int32 outputDim = 5;
    if (has_outputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->outputdim());
    }

  }
  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RNNStructParameter::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const RNNStructParameter* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const RNNStructParameter>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void RNNStructParameter::MergeFrom(const RNNStructParameter& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_numhiddenlayers()) {
      set_numhiddenlayers(from.numhiddenlayers());
    }
    if (from.has_hiddenlayerinputdim()) {
      set_hiddenlayerinputdim(from.hiddenlayerinputdim());
    }
    if (from.has_hiddenlayeroutputdim()) {
      set_hiddenlayeroutputdim(from.hiddenlayeroutputdim());
    }
    if (from.has_inputdim()) {
      set_inputdim(from.inputdim());
    }
    if (from.has_outputdim()) {
      set_outputdim(from.outputdim());
    }
  }
  if (from._internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->MergeFrom(from.unknown_fields());
  }
}

void RNNStructParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RNNStructParameter::CopyFrom(const RNNStructParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RNNStructParameter::IsInitialized() const {

  return true;
}

void RNNStructParameter::Swap(RNNStructParameter* other) {
  if (other == this) return;
  InternalSwap(other);
}
void RNNStructParameter::InternalSwap(RNNStructParameter* other) {
  std::swap(numhiddenlayers_, other->numhiddenlayers_);
  std::swap(hiddenlayerinputdim_, other->hiddenlayerinputdim_);
  std::swap(hiddenlayeroutputdim_, other->hiddenlayeroutputdim_);
  std::swap(inputdim_, other->inputdim_);
  std::swap(outputdim_, other->outputdim_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata RNNStructParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RNNStructParameter_descriptor_;
  metadata.reflection = RNNStructParameter_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// RNNStructParameter

// optional int32 numHiddenLayers = 1;
bool RNNStructParameter::has_numhiddenlayers() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void RNNStructParameter::set_has_numhiddenlayers() {
  _has_bits_[0] |= 0x00000001u;
}
void RNNStructParameter::clear_has_numhiddenlayers() {
  _has_bits_[0] &= ~0x00000001u;
}
void RNNStructParameter::clear_numhiddenlayers() {
  numhiddenlayers_ = 0;
  clear_has_numhiddenlayers();
}
 ::google::protobuf::int32 RNNStructParameter::numhiddenlayers() const {
  // @@protoc_insertion_point(field_get:DeepLearning.RNNStructParameter.numHiddenLayers)
  return numhiddenlayers_;
}
 void RNNStructParameter::set_numhiddenlayers(::google::protobuf::int32 value) {
  set_has_numhiddenlayers();
  numhiddenlayers_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.RNNStructParameter.numHiddenLayers)
}

// optional int32 hiddenLayerInputDim = 2;
bool RNNStructParameter::has_hiddenlayerinputdim() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void RNNStructParameter::set_has_hiddenlayerinputdim() {
  _has_bits_[0] |= 0x00000002u;
}
void RNNStructParameter::clear_has_hiddenlayerinputdim() {
  _has_bits_[0] &= ~0x00000002u;
}
void RNNStructParameter::clear_hiddenlayerinputdim() {
  hiddenlayerinputdim_ = 0;
  clear_has_hiddenlayerinputdim();
}
 ::google::protobuf::int32 RNNStructParameter::hiddenlayerinputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.RNNStructParameter.hiddenLayerInputDim)
  return hiddenlayerinputdim_;
}
 void RNNStructParameter::set_hiddenlayerinputdim(::google::protobuf::int32 value) {
  set_has_hiddenlayerinputdim();
  hiddenlayerinputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.RNNStructParameter.hiddenLayerInputDim)
}

// optional int32 hiddenLayerOutputDim = 3;
bool RNNStructParameter::has_hiddenlayeroutputdim() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
void RNNStructParameter::set_has_hiddenlayeroutputdim() {
  _has_bits_[0] |= 0x00000004u;
}
void RNNStructParameter::clear_has_hiddenlayeroutputdim() {
  _has_bits_[0] &= ~0x00000004u;
}
void RNNStructParameter::clear_hiddenlayeroutputdim() {
  hiddenlayeroutputdim_ = 0;
  clear_has_hiddenlayeroutputdim();
}
 ::google::protobuf::int32 RNNStructParameter::hiddenlayeroutputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.RNNStructParameter.hiddenLayerOutputDim)
  return hiddenlayeroutputdim_;
}
 void RNNStructParameter::set_hiddenlayeroutputdim(::google::protobuf::int32 value) {
  set_has_hiddenlayeroutputdim();
  hiddenlayeroutputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.RNNStructParameter.hiddenLayerOutputDim)
}

// optional int32 inputDim = 4;
bool RNNStructParameter::has_inputdim() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
void RNNStructParameter::set_has_inputdim() {
  _has_bits_[0] |= 0x00000008u;
}
void RNNStructParameter::clear_has_inputdim() {
  _has_bits_[0] &= ~0x00000008u;
}
void RNNStructParameter::clear_inputdim() {
  inputdim_ = 0;
  clear_has_inputdim();
}
 ::google::protobuf::int32 RNNStructParameter::inputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.RNNStructParameter.inputDim)
  return inputdim_;
}
 void RNNStructParameter::set_inputdim(::google::protobuf::int32 value) {
  set_has_inputdim();
  inputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.RNNStructParameter.inputDim)
}

// optional int32 outputDim = 5;
bool RNNStructParameter::has_outputdim() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
void RNNStructParameter::set_has_outputdim() {
  _has_bits_[0] |= 0x00000010u;
}
void RNNStructParameter::clear_has_outputdim() {
  _has_bits_[0] &= ~0x00000010u;
}
void RNNStructParameter::clear_outputdim() {
  outputdim_ = 0;
  clear_has_outputdim();
}
 ::google::protobuf::int32 RNNStructParameter::outputdim() const {
  // @@protoc_insertion_point(field_get:DeepLearning.RNNStructParameter.outputDim)
  return outputdim_;
}
 void RNNStructParameter::set_outputdim(::google::protobuf::int32 value) {
  set_has_outputdim();
  outputdim_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.RNNStructParameter.outputDim)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

const ::google::protobuf::EnumDescriptor* NeuralNetTrainingParameter_TrainerType_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NeuralNetTrainingParameter_TrainerType_descriptor_;
}
bool NeuralNetTrainingParameter_TrainerType_IsValid(int value) {
  switch(value) {
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#ifndef _MSC_VER
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::SGD;
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::iRProp;
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::TrainerType_MIN;
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::TrainerType_MAX;
const int NeuralNetTrainingParameter::TrainerType_ARRAYSIZE;
#endif  // _MSC_VER
#ifndef _MSC_VER
const int NeuralNetTrainingParameter::kLearningRateFieldNumber;
const int NeuralNetTrainingParameter::kMaxIterFieldNumber;
const int NeuralNetTrainingParameter::kMiniBatchSizeFieldNumber;
const int NeuralNetTrainingParameter::kNEpochFieldNumber;
const int NeuralNetTrainingParameter::kEpiFieldNumber;
const int NeuralNetTrainingParameter::kTrainerTypeFieldNumber;
const int NeuralNetTrainingParameter::kDecayRateFieldNumber;
const int NeuralNetTrainingParameter::kMomentumFieldNumber;
const int NeuralNetTrainingParameter::kVerboseFieldNumber;
const int NeuralNetTrainingParameter::kPrintInfoFrequencyFieldNumber;
#endif  // !_MSC_VER

NeuralNetTrainingParameter::NeuralNetTrainingParameter()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.NeuralNetTrainingParameter)
}

void NeuralNetTrainingParameter::InitAsDefaultInstance() {
}

NeuralNetTrainingParameter::NeuralNetTrainingParameter(const NeuralNetTrainingParameter& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.NeuralNetTrainingParameter)
}

void NeuralNetTrainingParameter::SharedCtor() {
  _cached_size_ = 0;
  learningrate_ = 0;
  maxiter_ = 0;
  minibatchsize_ = 0;
  nepoch_ = 0;
  epi_ = 1e-06;
  trainertype_ = 1;
  decayrate_ = 10;
  momentum_ = 0.9;
  verbose_ = true;
  printinfofrequency_ = 1;
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

NeuralNetTrainingParameter::~NeuralNetTrainingParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.NeuralNetTrainingParameter)
  SharedDtor();
}

void NeuralNetTrainingParameter::SharedDtor() {
  if (this != default_instance_) {
  }
}

void NeuralNetTrainingParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* NeuralNetTrainingParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NeuralNetTrainingParameter_descriptor_;
}

const NeuralNetTrainingParameter& NeuralNetTrainingParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

NeuralNetTrainingParameter* NeuralNetTrainingParameter::default_instance_ = NULL;

NeuralNetTrainingParameter* NeuralNetTrainingParameter::New(::google::protobuf::Arena* arena) const {
  NeuralNetTrainingParameter* n = new NeuralNetTrainingParameter;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void NeuralNetTrainingParameter::Clear() {
#define ZR_HELPER_(f) reinterpret_cast<char*>(\
  &reinterpret_cast<NeuralNetTrainingParameter*>(16)->f)

#define ZR_(first, last) do {\
  ::memset(&first, 0,\
           ZR_HELPER_(last) - ZR_HELPER_(first) + sizeof(last));\
} while (0)

  if (_has_bits_[0 / 32] & 255u) {
    ZR_(learningrate_, minibatchsize_);
    nepoch_ = 0;
    epi_ = 1e-06;
    trainertype_ = 1;
    decayrate_ = 10;
    momentum_ = 0.9;
  }
  if (_has_bits_[8 / 32] & 768u) {
    verbose_ = true;
    printinfofrequency_ = 1;
  }

#undef ZR_HELPER_
#undef ZR_

  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  if (_internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->Clear();
  }
}

bool NeuralNetTrainingParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.NeuralNetTrainingParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional double learningRate = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &learningrate_)));
          set_has_learningrate();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_maxIter;
        break;
      }

      // optional int32 maxIter = 2;
      case 2: {
        if (tag == 16) {
         parse_maxIter:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &maxiter_)));
          set_has_maxiter();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_miniBatchSize;
        break;
      }

      // optional int32 miniBatchSize = 3;
      case 3: {
        if (tag == 24) {
         parse_miniBatchSize:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &minibatchsize_)));
          set_has_minibatchsize();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_NEpoch;
        break;
      }

      // optional int32 NEpoch = 4;
      case 4: {
        if (tag == 32) {
         parse_NEpoch:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &nepoch_)));
          set_has_nepoch();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(41)) goto parse_epi;
        break;
      }

      // optional double epi = 5 [default = 1e-06];
      case 5: {
        if (tag == 41) {
         parse_epi:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &epi_)));
          set_has_epi();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(48)) goto parse_trainerType;
        break;
      }

      // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
      case 6: {
        if (tag == 48) {
         parse_trainerType:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::DeepLearning::NeuralNetTrainingParameter_TrainerType_IsValid(value)) {
            set_trainertype(static_cast< ::DeepLearning::NeuralNetTrainingParameter_TrainerType >(value));
          } else {
            mutable_unknown_fields()->AddVarint(6, value);
          }
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(57)) goto parse_decayRate;
        break;
      }

      // optional double decayRate = 7 [default = 10];
      case 7: {
        if (tag == 57) {
         parse_decayRate:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &decayrate_)));
          set_has_decayrate();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(65)) goto parse_momentum;
        break;
      }

      // optional double momentum = 8 [default = 0.9];
      case 8: {
        if (tag == 65) {
         parse_momentum:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &momentum_)));
          set_has_momentum();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(72)) goto parse_verbose;
        break;
      }

      // optional bool verbose = 9 [default = true];
      case 9: {
        if (tag == 72) {
         parse_verbose:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &verbose_)));
          set_has_verbose();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(80)) goto parse_printInfoFrequency;
        break;
      }

      // optional int32 printInfoFrequency = 10 [default = 1];
      case 10: {
        if (tag == 80) {
         parse_printInfoFrequency:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &printinfofrequency_)));
          set_has_printinfofrequency();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.NeuralNetTrainingParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.NeuralNetTrainingParameter)
  return false;
#undef DO_
}

void NeuralNetTrainingParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.NeuralNetTrainingParameter)
  // optional double learningRate = 1;
  if (has_learningrate()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(1, this->learningrate(), output);
  }

  // optional int32 maxIter = 2;
  if (has_maxiter()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->maxiter(), output);
  }

  // optional int32 miniBatchSize = 3;
  if (has_minibatchsize()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->minibatchsize(), output);
  }

  // optional int32 NEpoch = 4;
  if (has_nepoch()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(4, this->nepoch(), output);
  }

  // optional double epi = 5 [default = 1e-06];
  if (has_epi()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(5, this->epi(), output);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
  if (has_trainertype()) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      6, this->trainertype(), output);
  }

  // optional double decayRate = 7 [default = 10];
  if (has_decayrate()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(7, this->decayrate(), output);
  }

  // optional double momentum = 8 [default = 0.9];
  if (has_momentum()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(8, this->momentum(), output);
  }

  // optional bool verbose = 9 [default = true];
  if (has_verbose()) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(9, this->verbose(), output);
  }

  // optional int32 printInfoFrequency = 10 [default = 1];
  if (has_printinfofrequency()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(10, this->printinfofrequency(), output);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.NeuralNetTrainingParameter)
}

::google::protobuf::uint8* NeuralNetTrainingParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.NeuralNetTrainingParameter)
  // optional double learningRate = 1;
  if (has_learningrate()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(1, this->learningrate(), target);
  }

  // optional int32 maxIter = 2;
  if (has_maxiter()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->maxiter(), target);
  }

  // optional int32 miniBatchSize = 3;
  if (has_minibatchsize()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->minibatchsize(), target);
  }

  // optional int32 NEpoch = 4;
  if (has_nepoch()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(4, this->nepoch(), target);
  }

  // optional double epi = 5 [default = 1e-06];
  if (has_epi()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(5, this->epi(), target);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
  if (has_trainertype()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      6, this->trainertype(), target);
  }

  // optional double decayRate = 7 [default = 10];
  if (has_decayrate()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(7, this->decayrate(), target);
  }

  // optional double momentum = 8 [default = 0.9];
  if (has_momentum()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(8, this->momentum(), target);
  }

  // optional bool verbose = 9 [default = true];
  if (has_verbose()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(9, this->verbose(), target);
  }

  // optional int32 printInfoFrequency = 10 [default = 1];
  if (has_printinfofrequency()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(10, this->printinfofrequency(), target);
  }

  if (_internal_metadata_.have_unknown_fields()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.NeuralNetTrainingParameter)
  return target;
}

int NeuralNetTrainingParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & 255) {
    // optional double learningRate = 1;
    if (has_learningrate()) {
      total_size += 1 + 8;
    }

    // optional int32 maxIter = 2;
    if (has_maxiter()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->maxiter());
    }

    // optional int32 miniBatchSize = 3;
    if (has_minibatchsize()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->minibatchsize());
    }

    // optional int32 NEpoch = 4;
    if (has_nepoch()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->nepoch());
    }

    // optional double epi = 5 [default = 1e-06];
    if (has_epi()) {
      total_size += 1 + 8;
    }

    // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
    if (has_trainertype()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::EnumSize(this->trainertype());
    }

    // optional double decayRate = 7 [default = 10];
    if (has_decayrate()) {
      total_size += 1 + 8;
    }

    // optional double momentum = 8 [default = 0.9];
    if (has_momentum()) {
      total_size += 1 + 8;
    }

  }
  if (_has_bits_[8 / 32] & 768) {
    // optional bool verbose = 9 [default = true];
    if (has_verbose()) {
      total_size += 1 + 1;
    }

    // optional int32 printInfoFrequency = 10 [default = 1];
    if (has_printinfofrequency()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->printinfofrequency());
    }

  }
  if (_internal_metadata_.have_unknown_fields()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void NeuralNetTrainingParameter::MergeFrom(const ::google::protobuf::Message& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const NeuralNetTrainingParameter* source = 
      ::google::protobuf::internal::DynamicCastToGenerated<const NeuralNetTrainingParameter>(
          &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void NeuralNetTrainingParameter::MergeFrom(const NeuralNetTrainingParameter& from) {
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_learningrate()) {
      set_learningrate(from.learningrate());
    }
    if (from.has_maxiter()) {
      set_maxiter(from.maxiter());
    }
    if (from.has_minibatchsize()) {
      set_minibatchsize(from.minibatchsize());
    }
    if (from.has_nepoch()) {
      set_nepoch(from.nepoch());
    }
    if (from.has_epi()) {
      set_epi(from.epi());
    }
    if (from.has_trainertype()) {
      set_trainertype(from.trainertype());
    }
    if (from.has_decayrate()) {
      set_decayrate(from.decayrate());
    }
    if (from.has_momentum()) {
      set_momentum(from.momentum());
    }
  }
  if (from._has_bits_[8 / 32] & (0xffu << (8 % 32))) {
    if (from.has_verbose()) {
      set_verbose(from.verbose());
    }
    if (from.has_printinfofrequency()) {
      set_printinfofrequency(from.printinfofrequency());
    }
  }
  if (from._internal_metadata_.have_unknown_fields()) {
    mutable_unknown_fields()->MergeFrom(from.unknown_fields());
  }
}

void NeuralNetTrainingParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void NeuralNetTrainingParameter::CopyFrom(const NeuralNetTrainingParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool NeuralNetTrainingParameter::IsInitialized() const {

  return true;
}

void NeuralNetTrainingParameter::Swap(NeuralNetTrainingParameter* other) {
  if (other == this) return;
  InternalSwap(other);
}
void NeuralNetTrainingParameter::InternalSwap(NeuralNetTrainingParameter* other) {
  std::swap(learningrate_, other->learningrate_);
  std::swap(maxiter_, other->maxiter_);
  std::swap(minibatchsize_, other->minibatchsize_);
  std::swap(nepoch_, other->nepoch_);
  std::swap(epi_, other->epi_);
  std::swap(trainertype_, other->trainertype_);
  std::swap(decayrate_, other->decayrate_);
  std::swap(momentum_, other->momentum_);
  std::swap(verbose_, other->verbose_);
  std::swap(printinfofrequency_, other->printinfofrequency_);
  std::swap(_has_bits_[0], other->_has_bits_[0]);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata NeuralNetTrainingParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = NeuralNetTrainingParameter_descriptor_;
  metadata.reflection = NeuralNetTrainingParameter_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// NeuralNetTrainingParameter

// optional double learningRate = 1;
bool NeuralNetTrainingParameter::has_learningrate() const {
  return (_has_bits_[0] & 0x00000001u) != 0;
}
void NeuralNetTrainingParameter::set_has_learningrate() {
  _has_bits_[0] |= 0x00000001u;
}
void NeuralNetTrainingParameter::clear_has_learningrate() {
  _has_bits_[0] &= ~0x00000001u;
}
void NeuralNetTrainingParameter::clear_learningrate() {
  learningrate_ = 0;
  clear_has_learningrate();
}
 double NeuralNetTrainingParameter::learningrate() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.learningRate)
  return learningrate_;
}
 void NeuralNetTrainingParameter::set_learningrate(double value) {
  set_has_learningrate();
  learningrate_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.learningRate)
}

// optional int32 maxIter = 2;
bool NeuralNetTrainingParameter::has_maxiter() const {
  return (_has_bits_[0] & 0x00000002u) != 0;
}
void NeuralNetTrainingParameter::set_has_maxiter() {
  _has_bits_[0] |= 0x00000002u;
}
void NeuralNetTrainingParameter::clear_has_maxiter() {
  _has_bits_[0] &= ~0x00000002u;
}
void NeuralNetTrainingParameter::clear_maxiter() {
  maxiter_ = 0;
  clear_has_maxiter();
}
 ::google::protobuf::int32 NeuralNetTrainingParameter::maxiter() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.maxIter)
  return maxiter_;
}
 void NeuralNetTrainingParameter::set_maxiter(::google::protobuf::int32 value) {
  set_has_maxiter();
  maxiter_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.maxIter)
}

// optional int32 miniBatchSize = 3;
bool NeuralNetTrainingParameter::has_minibatchsize() const {
  return (_has_bits_[0] & 0x00000004u) != 0;
}
void NeuralNetTrainingParameter::set_has_minibatchsize() {
  _has_bits_[0] |= 0x00000004u;
}
void NeuralNetTrainingParameter::clear_has_minibatchsize() {
  _has_bits_[0] &= ~0x00000004u;
}
void NeuralNetTrainingParameter::clear_minibatchsize() {
  minibatchsize_ = 0;
  clear_has_minibatchsize();
}
 ::google::protobuf::int32 NeuralNetTrainingParameter::minibatchsize() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.miniBatchSize)
  return minibatchsize_;
}
 void NeuralNetTrainingParameter::set_minibatchsize(::google::protobuf::int32 value) {
  set_has_minibatchsize();
  minibatchsize_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.miniBatchSize)
}

// optional int32 NEpoch = 4;
bool NeuralNetTrainingParameter::has_nepoch() const {
  return (_has_bits_[0] & 0x00000008u) != 0;
}
void NeuralNetTrainingParameter::set_has_nepoch() {
  _has_bits_[0] |= 0x00000008u;
}
void NeuralNetTrainingParameter::clear_has_nepoch() {
  _has_bits_[0] &= ~0x00000008u;
}
void NeuralNetTrainingParameter::clear_nepoch() {
  nepoch_ = 0;
  clear_has_nepoch();
}
 ::google::protobuf::int32 NeuralNetTrainingParameter::nepoch() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.NEpoch)
  return nepoch_;
}
 void NeuralNetTrainingParameter::set_nepoch(::google::protobuf::int32 value) {
  set_has_nepoch();
  nepoch_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.NEpoch)
}

// optional double epi = 5 [default = 1e-06];
bool NeuralNetTrainingParameter::has_epi() const {
  return (_has_bits_[0] & 0x00000010u) != 0;
}
void NeuralNetTrainingParameter::set_has_epi() {
  _has_bits_[0] |= 0x00000010u;
}
void NeuralNetTrainingParameter::clear_has_epi() {
  _has_bits_[0] &= ~0x00000010u;
}
void NeuralNetTrainingParameter::clear_epi() {
  epi_ = 1e-06;
  clear_has_epi();
}
 double NeuralNetTrainingParameter::epi() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.epi)
  return epi_;
}
 void NeuralNetTrainingParameter::set_epi(double value) {
  set_has_epi();
  epi_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.epi)
}

// optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
bool NeuralNetTrainingParameter::has_trainertype() const {
  return (_has_bits_[0] & 0x00000020u) != 0;
}
void NeuralNetTrainingParameter::set_has_trainertype() {
  _has_bits_[0] |= 0x00000020u;
}
void NeuralNetTrainingParameter::clear_has_trainertype() {
  _has_bits_[0] &= ~0x00000020u;
}
void NeuralNetTrainingParameter::clear_trainertype() {
  trainertype_ = 1;
  clear_has_trainertype();
}
 ::DeepLearning::NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::trainertype() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.trainerType)
  return static_cast< ::DeepLearning::NeuralNetTrainingParameter_TrainerType >(trainertype_);
}
 void NeuralNetTrainingParameter::set_trainertype(::DeepLearning::NeuralNetTrainingParameter_TrainerType value) {
  assert(::DeepLearning::NeuralNetTrainingParameter_TrainerType_IsValid(value));
  set_has_trainertype();
  trainertype_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.trainerType)
}

// optional double decayRate = 7 [default = 10];
bool NeuralNetTrainingParameter::has_decayrate() const {
  return (_has_bits_[0] & 0x00000040u) != 0;
}
void NeuralNetTrainingParameter::set_has_decayrate() {
  _has_bits_[0] |= 0x00000040u;
}
void NeuralNetTrainingParameter::clear_has_decayrate() {
  _has_bits_[0] &= ~0x00000040u;
}
void NeuralNetTrainingParameter::clear_decayrate() {
  decayrate_ = 10;
  clear_has_decayrate();
}
 double NeuralNetTrainingParameter::decayrate() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.decayRate)
  return decayrate_;
}
 void NeuralNetTrainingParameter::set_decayrate(double value) {
  set_has_decayrate();
  decayrate_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.decayRate)
}

// optional double momentum = 8 [default = 0.9];
bool NeuralNetTrainingParameter::has_momentum() const {
  return (_has_bits_[0] & 0x00000080u) != 0;
}
void NeuralNetTrainingParameter::set_has_momentum() {
  _has_bits_[0] |= 0x00000080u;
}
void NeuralNetTrainingParameter::clear_has_momentum() {
  _has_bits_[0] &= ~0x00000080u;
}
void NeuralNetTrainingParameter::clear_momentum() {
  momentum_ = 0.9;
  clear_has_momentum();
}
 double NeuralNetTrainingParameter::momentum() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.momentum)
  return momentum_;
}
 void NeuralNetTrainingParameter::set_momentum(double value) {
  set_has_momentum();
  momentum_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.momentum)
}

// optional bool verbose = 9 [default = true];
bool NeuralNetTrainingParameter::has_verbose() const {
  return (_has_bits_[0] & 0x00000100u) != 0;
}
void NeuralNetTrainingParameter::set_has_verbose() {
  _has_bits_[0] |= 0x00000100u;
}
void NeuralNetTrainingParameter::clear_has_verbose() {
  _has_bits_[0] &= ~0x00000100u;
}
void NeuralNetTrainingParameter::clear_verbose() {
  verbose_ = true;
  clear_has_verbose();
}
 bool NeuralNetTrainingParameter::verbose() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.verbose)
  return verbose_;
}
 void NeuralNetTrainingParameter::set_verbose(bool value) {
  set_has_verbose();
  verbose_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.verbose)
}

// optional int32 printInfoFrequency = 10 [default = 1];
bool NeuralNetTrainingParameter::has_printinfofrequency() const {
  return (_has_bits_[0] & 0x00000200u) != 0;
}
void NeuralNetTrainingParameter::set_has_printinfofrequency() {
  _has_bits_[0] |= 0x00000200u;
}
void NeuralNetTrainingParameter::clear_has_printinfofrequency() {
  _has_bits_[0] &= ~0x00000200u;
}
void NeuralNetTrainingParameter::clear_printinfofrequency() {
  printinfofrequency_ = 1;
  clear_has_printinfofrequency();
}
 ::google::protobuf::int32 NeuralNetTrainingParameter::printinfofrequency() const {
  // @@protoc_insertion_point(field_get:DeepLearning.NeuralNetTrainingParameter.printInfoFrequency)
  return printinfofrequency_;
}
 void NeuralNetTrainingParameter::set_printinfofrequency(::google::protobuf::int32 value) {
  set_has_printinfofrequency();
  printinfofrequency_ = value;
  // @@protoc_insertion_point(field_set:DeepLearning.NeuralNetTrainingParameter.printInfoFrequency)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace DeepLearning

// @@protoc_insertion_point(global_scope)
