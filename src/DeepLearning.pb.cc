// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: DeepLearning.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "DeepLearning.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace DeepLearning {

namespace {

const ::google::protobuf::Descriptor* NeuralNetParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  NeuralNetParameter_reflection_ = NULL;
const ::google::protobuf::Descriptor* LayerStructParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  LayerStructParameter_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* LayerStructParameter_ActivationType_descriptor_ = NULL;
const ::google::protobuf::Descriptor* RNNStructParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  RNNStructParameter_reflection_ = NULL;
const ::google::protobuf::Descriptor* NeuralNetTrainingParameter_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  NeuralNetTrainingParameter_reflection_ = NULL;
const ::google::protobuf::EnumDescriptor* NeuralNetTrainingParameter_TrainerType_descriptor_ = NULL;

}  // namespace


void protobuf_AssignDesc_DeepLearning_2eproto() {
  protobuf_AddDesc_DeepLearning_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "DeepLearning.proto");
  GOOGLE_CHECK(file != NULL);
  NeuralNetParameter_descriptor_ = file->message_type(0);
  static const int NeuralNetParameter_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, type_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, layerstruct_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, neuralnettrainingparameter_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, rnnstruct_),
  };
  NeuralNetParameter_reflection_ =
    new ::google::protobuf::internal::GeneratedMessageReflection(
      NeuralNetParameter_descriptor_,
      NeuralNetParameter::default_instance_,
      NeuralNetParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, _has_bits_[0]),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetParameter, _unknown_fields_),
      -1,
      ::google::protobuf::DescriptorPool::generated_pool(),
      ::google::protobuf::MessageFactory::generated_factory(),
      sizeof(NeuralNetParameter));
  LayerStructParameter_descriptor_ = file->message_type(1);
  static const int LayerStructParameter_offsets_[5] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, inputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, outputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, activationtype_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, name_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, type_),
  };
  LayerStructParameter_reflection_ =
    new ::google::protobuf::internal::GeneratedMessageReflection(
      LayerStructParameter_descriptor_,
      LayerStructParameter::default_instance_,
      LayerStructParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, _has_bits_[0]),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(LayerStructParameter, _unknown_fields_),
      -1,
      ::google::protobuf::DescriptorPool::generated_pool(),
      ::google::protobuf::MessageFactory::generated_factory(),
      sizeof(LayerStructParameter));
  LayerStructParameter_ActivationType_descriptor_ = LayerStructParameter_descriptor_->enum_type(0);
  RNNStructParameter_descriptor_ = file->message_type(2);
  static const int RNNStructParameter_offsets_[6] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, numhiddenlayers_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, hiddenlayerinputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, hiddenlayeroutputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, inputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, outputdim_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, timeserieslength_),
  };
  RNNStructParameter_reflection_ =
    new ::google::protobuf::internal::GeneratedMessageReflection(
      RNNStructParameter_descriptor_,
      RNNStructParameter::default_instance_,
      RNNStructParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, _has_bits_[0]),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(RNNStructParameter, _unknown_fields_),
      -1,
      ::google::protobuf::DescriptorPool::generated_pool(),
      ::google::protobuf::MessageFactory::generated_factory(),
      sizeof(RNNStructParameter));
  NeuralNetTrainingParameter_descriptor_ = file->message_type(3);
  static const int NeuralNetTrainingParameter_offsets_[8] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, learningrate_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, maxiter_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, minibatchsize_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, nepoch_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, epi_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, trainertype_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, decayrate_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, momentum_),
  };
  NeuralNetTrainingParameter_reflection_ =
    new ::google::protobuf::internal::GeneratedMessageReflection(
      NeuralNetTrainingParameter_descriptor_,
      NeuralNetTrainingParameter::default_instance_,
      NeuralNetTrainingParameter_offsets_,
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, _has_bits_[0]),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(NeuralNetTrainingParameter, _unknown_fields_),
      -1,
      ::google::protobuf::DescriptorPool::generated_pool(),
      ::google::protobuf::MessageFactory::generated_factory(),
      sizeof(NeuralNetTrainingParameter));
  NeuralNetTrainingParameter_TrainerType_descriptor_ = NeuralNetTrainingParameter_descriptor_->enum_type(0);
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
inline void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_DeepLearning_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
    NeuralNetParameter_descriptor_, &NeuralNetParameter::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
    LayerStructParameter_descriptor_, &LayerStructParameter::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
    RNNStructParameter_descriptor_, &RNNStructParameter::default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
    NeuralNetTrainingParameter_descriptor_, &NeuralNetTrainingParameter::default_instance());
}

}  // namespace

void protobuf_ShutdownFile_DeepLearning_2eproto() {
  delete NeuralNetParameter::default_instance_;
  delete NeuralNetParameter_reflection_;
  delete LayerStructParameter::default_instance_;
  delete LayerStructParameter_reflection_;
  delete RNNStructParameter::default_instance_;
  delete RNNStructParameter_reflection_;
  delete NeuralNetTrainingParameter::default_instance_;
  delete NeuralNetTrainingParameter_reflection_;
}

void protobuf_AddDesc_DeepLearning_2eproto() {
  static bool already_here = false;
  if (already_here) return;
  already_here = true;
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n\022DeepLearning.proto\022\014DeepLearning\"\354\001\n\022N"
    "euralNetParameter\022\014\n\004name\030\001 \001(\t\022\014\n\004type\030"
    "\002 \001(\t\0227\n\013layerStruct\030d \003(\0132\".DeepLearnin"
    "g.LayerStructParameter\022L\n\032neuralNetTrain"
    "ingParameter\030e \001(\0132(.DeepLearning.Neural"
    "NetTrainingParameter\0223\n\trnnStruct\030f \001(\0132"
    " .DeepLearning.RNNStructParameter\"\344\001\n\024La"
    "yerStructParameter\022\020\n\010inputDim\030\001 \001(\005\022\021\n\t"
    "outputDim\030\002 \001(\005\022I\n\016activationType\030\003 \001(\0162"
    "1.DeepLearning.LayerStructParameter.Acti"
    "vationType\022\014\n\004name\030\004 \001(\t\022\014\n\004type\030\005 \001(\t\"@"
    "\n\016ActivationType\022\013\n\007sigmoid\020\001\022\010\n\004tanh\020\002\022"
    "\n\n\006linear\020\003\022\013\n\007softmax\020\004\"\247\001\n\022RNNStructPa"
    "rameter\022\027\n\017numHiddenLayers\030\001 \001(\005\022\033\n\023hidd"
    "enLayerInputDim\030\002 \001(\005\022\034\n\024hiddenLayerOutp"
    "utDim\030\003 \001(\005\022\020\n\010inputDim\030\004 \001(\005\022\021\n\toutputD"
    "im\030\005 \001(\005\022\030\n\020timeSeriesLength\030\006 \001(\005\"\240\002\n\032N"
    "euralNetTrainingParameter\022\024\n\014learningRat"
    "e\030\001 \001(\001\022\017\n\007maxIter\030\002 \001(\005\022\025\n\rminiBatchSiz"
    "e\030\003 \001(\005\022\016\n\006NEpoch\030\004 \001(\005\022\022\n\003epi\030\005 \001(\001:\0051e"
    "-06\022N\n\013trainerType\030\006 \001(\01624.DeepLearning."
    "NeuralNetTrainingParameter.TrainerType:\003"
    "SGD\022\025\n\tdecayRate\030\007 \001(\001:\00210\022\025\n\010momentum\030\010"
    " \001(\001:\0030.9\"\"\n\013TrainerType\022\007\n\003SGD\020\001\022\n\n\006iRP"
    "rop\020\002", 965);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "DeepLearning.proto", &protobuf_RegisterTypes);
  NeuralNetParameter::default_instance_ = new NeuralNetParameter();
  LayerStructParameter::default_instance_ = new LayerStructParameter();
  RNNStructParameter::default_instance_ = new RNNStructParameter();
  NeuralNetTrainingParameter::default_instance_ = new NeuralNetTrainingParameter();
  NeuralNetParameter::default_instance_->InitAsDefaultInstance();
  LayerStructParameter::default_instance_->InitAsDefaultInstance();
  RNNStructParameter::default_instance_->InitAsDefaultInstance();
  NeuralNetTrainingParameter::default_instance_->InitAsDefaultInstance();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_DeepLearning_2eproto);
}

// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_DeepLearning_2eproto {
  StaticDescriptorInitializer_DeepLearning_2eproto() {
    protobuf_AddDesc_DeepLearning_2eproto();
  }
} static_descriptor_initializer_DeepLearning_2eproto_;

// ===================================================================

#ifndef _MSC_VER
const int NeuralNetParameter::kNameFieldNumber;
const int NeuralNetParameter::kTypeFieldNumber;
const int NeuralNetParameter::kLayerStructFieldNumber;
const int NeuralNetParameter::kNeuralNetTrainingParameterFieldNumber;
const int NeuralNetParameter::kRnnStructFieldNumber;
#endif  // !_MSC_VER

NeuralNetParameter::NeuralNetParameter()
  : ::google::protobuf::Message() {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.NeuralNetParameter)
}

void NeuralNetParameter::InitAsDefaultInstance() {
  neuralnettrainingparameter_ = const_cast< ::DeepLearning::NeuralNetTrainingParameter*>(&::DeepLearning::NeuralNetTrainingParameter::default_instance());
  rnnstruct_ = const_cast< ::DeepLearning::RNNStructParameter*>(&::DeepLearning::RNNStructParameter::default_instance());
}

NeuralNetParameter::NeuralNetParameter(const NeuralNetParameter& from)
  : ::google::protobuf::Message() {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.NeuralNetParameter)
}

void NeuralNetParameter::SharedCtor() {
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  neuralnettrainingparameter_ = NULL;
  rnnstruct_ = NULL;
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

NeuralNetParameter::~NeuralNetParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.NeuralNetParameter)
  SharedDtor();
}

void NeuralNetParameter::SharedDtor() {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete name_;
  }
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete type_;
  }
  if (this != default_instance_) {
    delete neuralnettrainingparameter_;
    delete rnnstruct_;
  }
}

void NeuralNetParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* NeuralNetParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NeuralNetParameter_descriptor_;
}

const NeuralNetParameter& NeuralNetParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

NeuralNetParameter* NeuralNetParameter::default_instance_ = NULL;

NeuralNetParameter* NeuralNetParameter::New() const {
  return new NeuralNetParameter;
}

void NeuralNetParameter::Clear() {
  if (_has_bits_[0 / 32] & 27) {
    if (has_name()) {
      if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
        name_->clear();
      }
    }
    if (has_type()) {
      if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
        type_->clear();
      }
    }
    if (has_neuralnettrainingparameter()) {
      if (neuralnettrainingparameter_ != NULL) neuralnettrainingparameter_->::DeepLearning::NeuralNetTrainingParameter::Clear();
    }
    if (has_rnnstruct()) {
      if (rnnstruct_ != NULL) rnnstruct_->::DeepLearning::RNNStructParameter::Clear();
    }
  }
  layerstruct_.Clear();
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  mutable_unknown_fields()->Clear();
}

bool NeuralNetParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.NeuralNetParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(16383);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional string name = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "name");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_type;
        break;
      }

      // optional string type = 2;
      case 2: {
        if (tag == 18) {
         parse_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_type()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->type().data(), this->type().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "type");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(802)) goto parse_layerStruct;
        break;
      }

      // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
      case 100: {
        if (tag == 802) {
         parse_layerStruct:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
                input, add_layerstruct()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(802)) goto parse_layerStruct;
        if (input->ExpectTag(810)) goto parse_neuralNetTrainingParameter;
        break;
      }

      // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
      case 101: {
        if (tag == 810) {
         parse_neuralNetTrainingParameter:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_neuralnettrainingparameter()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(818)) goto parse_rnnStruct;
        break;
      }

      // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
      case 102: {
        if (tag == 818) {
         parse_rnnStruct:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_rnnstruct()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.NeuralNetParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.NeuralNetParameter)
  return false;
#undef DO_
}

void NeuralNetParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.NeuralNetParameter)
  // optional string name = 1;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->name(), output);
  }

  // optional string type = 2;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->type(), output);
  }

  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  for (int i = 0; i < this->layerstruct_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      100, this->layerstruct(i), output);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
  if (has_neuralnettrainingparameter()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      101, this->neuralnettrainingparameter(), output);
  }

  // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
  if (has_rnnstruct()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      102, this->rnnstruct(), output);
  }

  if (!unknown_fields().empty()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.NeuralNetParameter)
}

::google::protobuf::uint8* NeuralNetParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.NeuralNetParameter)
  // optional string name = 1;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->name(), target);
  }

  // optional string type = 2;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->type(), target);
  }

  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  for (int i = 0; i < this->layerstruct_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        100, this->layerstruct(i), target);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
  if (has_neuralnettrainingparameter()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        101, this->neuralnettrainingparameter(), target);
  }

  // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
  if (has_rnnstruct()) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteMessageNoVirtualToArray(
        102, this->rnnstruct(), target);
  }

  if (!unknown_fields().empty()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.NeuralNetParameter)
  return target;
}

int NeuralNetParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    // optional string name = 1;
    if (has_name()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->name());
    }

    // optional string type = 2;
    if (has_type()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->type());
    }

    // optional .DeepLearning.NeuralNetTrainingParameter neuralNetTrainingParameter = 101;
    if (has_neuralnettrainingparameter()) {
      total_size += 2 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->neuralnettrainingparameter());
    }

    // optional .DeepLearning.RNNStructParameter rnnStruct = 102;
    if (has_rnnstruct()) {
      total_size += 2 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->rnnstruct());
    }

  }
  // repeated .DeepLearning.LayerStructParameter layerStruct = 100;
  total_size += 2 * this->layerstruct_size();
  for (int i = 0; i < this->layerstruct_size(); i++) {
    total_size +=
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        this->layerstruct(i));
  }

  if (!unknown_fields().empty()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void NeuralNetParameter::MergeFrom(const ::google::protobuf::Message& from) {
  GOOGLE_CHECK_NE(&from, this);
  const NeuralNetParameter* source =
    ::google::protobuf::internal::dynamic_cast_if_available<const NeuralNetParameter*>(
      &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void NeuralNetParameter::MergeFrom(const NeuralNetParameter& from) {
  GOOGLE_CHECK_NE(&from, this);
  layerstruct_.MergeFrom(from.layerstruct_);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_name()) {
      set_name(from.name());
    }
    if (from.has_type()) {
      set_type(from.type());
    }
    if (from.has_neuralnettrainingparameter()) {
      mutable_neuralnettrainingparameter()->::DeepLearning::NeuralNetTrainingParameter::MergeFrom(from.neuralnettrainingparameter());
    }
    if (from.has_rnnstruct()) {
      mutable_rnnstruct()->::DeepLearning::RNNStructParameter::MergeFrom(from.rnnstruct());
    }
  }
  mutable_unknown_fields()->MergeFrom(from.unknown_fields());
}

void NeuralNetParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void NeuralNetParameter::CopyFrom(const NeuralNetParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool NeuralNetParameter::IsInitialized() const {

  return true;
}

void NeuralNetParameter::Swap(NeuralNetParameter* other) {
  if (other != this) {
    std::swap(name_, other->name_);
    std::swap(type_, other->type_);
    layerstruct_.Swap(&other->layerstruct_);
    std::swap(neuralnettrainingparameter_, other->neuralnettrainingparameter_);
    std::swap(rnnstruct_, other->rnnstruct_);
    std::swap(_has_bits_[0], other->_has_bits_[0]);
    _unknown_fields_.Swap(&other->_unknown_fields_);
    std::swap(_cached_size_, other->_cached_size_);
  }
}

::google::protobuf::Metadata NeuralNetParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = NeuralNetParameter_descriptor_;
  metadata.reflection = NeuralNetParameter_reflection_;
  return metadata;
}


// ===================================================================

const ::google::protobuf::EnumDescriptor* LayerStructParameter_ActivationType_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LayerStructParameter_ActivationType_descriptor_;
}
bool LayerStructParameter_ActivationType_IsValid(int value) {
  switch(value) {
    case 1:
    case 2:
    case 3:
    case 4:
      return true;
    default:
      return false;
  }
}

#ifndef _MSC_VER
const LayerStructParameter_ActivationType LayerStructParameter::sigmoid;
const LayerStructParameter_ActivationType LayerStructParameter::tanh;
const LayerStructParameter_ActivationType LayerStructParameter::linear;
const LayerStructParameter_ActivationType LayerStructParameter::softmax;
const LayerStructParameter_ActivationType LayerStructParameter::ActivationType_MIN;
const LayerStructParameter_ActivationType LayerStructParameter::ActivationType_MAX;
const int LayerStructParameter::ActivationType_ARRAYSIZE;
#endif  // _MSC_VER
#ifndef _MSC_VER
const int LayerStructParameter::kInputDimFieldNumber;
const int LayerStructParameter::kOutputDimFieldNumber;
const int LayerStructParameter::kActivationTypeFieldNumber;
const int LayerStructParameter::kNameFieldNumber;
const int LayerStructParameter::kTypeFieldNumber;
#endif  // !_MSC_VER

LayerStructParameter::LayerStructParameter()
  : ::google::protobuf::Message() {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.LayerStructParameter)
}

void LayerStructParameter::InitAsDefaultInstance() {
}

LayerStructParameter::LayerStructParameter(const LayerStructParameter& from)
  : ::google::protobuf::Message() {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.LayerStructParameter)
}

void LayerStructParameter::SharedCtor() {
  ::google::protobuf::internal::GetEmptyString();
  _cached_size_ = 0;
  inputdim_ = 0;
  outputdim_ = 0;
  activationtype_ = 1;
  name_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  type_ = const_cast< ::std::string*>(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

LayerStructParameter::~LayerStructParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.LayerStructParameter)
  SharedDtor();
}

void LayerStructParameter::SharedDtor() {
  if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete name_;
  }
  if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
    delete type_;
  }
  if (this != default_instance_) {
  }
}

void LayerStructParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* LayerStructParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return LayerStructParameter_descriptor_;
}

const LayerStructParameter& LayerStructParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

LayerStructParameter* LayerStructParameter::default_instance_ = NULL;

LayerStructParameter* LayerStructParameter::New() const {
  return new LayerStructParameter;
}

void LayerStructParameter::Clear() {
#define OFFSET_OF_FIELD_(f) (reinterpret_cast<char*>(      \
  &reinterpret_cast<LayerStructParameter*>(16)->f) - \
   reinterpret_cast<char*>(16))

#define ZR_(first, last) do {                              \
    size_t f = OFFSET_OF_FIELD_(first);                    \
    size_t n = OFFSET_OF_FIELD_(last) - f + sizeof(last);  \
    ::memset(&first, 0, n);                                \
  } while (0)

  if (_has_bits_[0 / 32] & 31) {
    ZR_(inputdim_, outputdim_);
    activationtype_ = 1;
    if (has_name()) {
      if (name_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
        name_->clear();
      }
    }
    if (has_type()) {
      if (type_ != &::google::protobuf::internal::GetEmptyStringAlreadyInited()) {
        type_->clear();
      }
    }
  }

#undef OFFSET_OF_FIELD_
#undef ZR_

  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  mutable_unknown_fields()->Clear();
}

bool LayerStructParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.LayerStructParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int32 inputDim = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inputdim_)));
          set_has_inputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_outputDim;
        break;
      }

      // optional int32 outputDim = 2;
      case 2: {
        if (tag == 16) {
         parse_outputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &outputdim_)));
          set_has_outputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_activationType;
        break;
      }

      // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
      case 3: {
        if (tag == 24) {
         parse_activationType:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::DeepLearning::LayerStructParameter_ActivationType_IsValid(value)) {
            set_activationtype(static_cast< ::DeepLearning::LayerStructParameter_ActivationType >(value));
          } else {
            mutable_unknown_fields()->AddVarint(3, value);
          }
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_name;
        break;
      }

      // optional string name = 4;
      case 4: {
        if (tag == 34) {
         parse_name:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "name");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(42)) goto parse_type;
        break;
      }

      // optional string type = 5;
      case 5: {
        if (tag == 42) {
         parse_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_type()));
          ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
            this->type().data(), this->type().length(),
            ::google::protobuf::internal::WireFormat::PARSE,
            "type");
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.LayerStructParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.LayerStructParameter)
  return false;
#undef DO_
}

void LayerStructParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.LayerStructParameter)
  // optional int32 inputDim = 1;
  if (has_inputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->inputdim(), output);
  }

  // optional int32 outputDim = 2;
  if (has_outputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->outputdim(), output);
  }

  // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
  if (has_activationtype()) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->activationtype(), output);
  }

  // optional string name = 4;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      4, this->name(), output);
  }

  // optional string type = 5;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "type");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      5, this->type(), output);
  }

  if (!unknown_fields().empty()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.LayerStructParameter)
}

::google::protobuf::uint8* LayerStructParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.LayerStructParameter)
  // optional int32 inputDim = 1;
  if (has_inputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->inputdim(), target);
  }

  // optional int32 outputDim = 2;
  if (has_outputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->outputdim(), target);
  }

  // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
  if (has_activationtype()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->activationtype(), target);
  }

  // optional string name = 4;
  if (has_name()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        4, this->name(), target);
  }

  // optional string type = 5;
  if (has_type()) {
    ::google::protobuf::internal::WireFormat::VerifyUTF8StringNamedField(
      this->type().data(), this->type().length(),
      ::google::protobuf::internal::WireFormat::SERIALIZE,
      "type");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        5, this->type(), target);
  }

  if (!unknown_fields().empty()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.LayerStructParameter)
  return target;
}

int LayerStructParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    // optional int32 inputDim = 1;
    if (has_inputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->inputdim());
    }

    // optional int32 outputDim = 2;
    if (has_outputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->outputdim());
    }

    // optional .DeepLearning.LayerStructParameter.ActivationType activationType = 3;
    if (has_activationtype()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::EnumSize(this->activationtype());
    }

    // optional string name = 4;
    if (has_name()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->name());
    }

    // optional string type = 5;
    if (has_type()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::StringSize(
          this->type());
    }

  }
  if (!unknown_fields().empty()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void LayerStructParameter::MergeFrom(const ::google::protobuf::Message& from) {
  GOOGLE_CHECK_NE(&from, this);
  const LayerStructParameter* source =
    ::google::protobuf::internal::dynamic_cast_if_available<const LayerStructParameter*>(
      &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void LayerStructParameter::MergeFrom(const LayerStructParameter& from) {
  GOOGLE_CHECK_NE(&from, this);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_inputdim()) {
      set_inputdim(from.inputdim());
    }
    if (from.has_outputdim()) {
      set_outputdim(from.outputdim());
    }
    if (from.has_activationtype()) {
      set_activationtype(from.activationtype());
    }
    if (from.has_name()) {
      set_name(from.name());
    }
    if (from.has_type()) {
      set_type(from.type());
    }
  }
  mutable_unknown_fields()->MergeFrom(from.unknown_fields());
}

void LayerStructParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void LayerStructParameter::CopyFrom(const LayerStructParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool LayerStructParameter::IsInitialized() const {

  return true;
}

void LayerStructParameter::Swap(LayerStructParameter* other) {
  if (other != this) {
    std::swap(inputdim_, other->inputdim_);
    std::swap(outputdim_, other->outputdim_);
    std::swap(activationtype_, other->activationtype_);
    std::swap(name_, other->name_);
    std::swap(type_, other->type_);
    std::swap(_has_bits_[0], other->_has_bits_[0]);
    _unknown_fields_.Swap(&other->_unknown_fields_);
    std::swap(_cached_size_, other->_cached_size_);
  }
}

::google::protobuf::Metadata LayerStructParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = LayerStructParameter_descriptor_;
  metadata.reflection = LayerStructParameter_reflection_;
  return metadata;
}


// ===================================================================

#ifndef _MSC_VER
const int RNNStructParameter::kNumHiddenLayersFieldNumber;
const int RNNStructParameter::kHiddenLayerInputDimFieldNumber;
const int RNNStructParameter::kHiddenLayerOutputDimFieldNumber;
const int RNNStructParameter::kInputDimFieldNumber;
const int RNNStructParameter::kOutputDimFieldNumber;
const int RNNStructParameter::kTimeSeriesLengthFieldNumber;
#endif  // !_MSC_VER

RNNStructParameter::RNNStructParameter()
  : ::google::protobuf::Message() {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.RNNStructParameter)
}

void RNNStructParameter::InitAsDefaultInstance() {
}

RNNStructParameter::RNNStructParameter(const RNNStructParameter& from)
  : ::google::protobuf::Message() {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.RNNStructParameter)
}

void RNNStructParameter::SharedCtor() {
  _cached_size_ = 0;
  numhiddenlayers_ = 0;
  hiddenlayerinputdim_ = 0;
  hiddenlayeroutputdim_ = 0;
  inputdim_ = 0;
  outputdim_ = 0;
  timeserieslength_ = 0;
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

RNNStructParameter::~RNNStructParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.RNNStructParameter)
  SharedDtor();
}

void RNNStructParameter::SharedDtor() {
  if (this != default_instance_) {
  }
}

void RNNStructParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* RNNStructParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return RNNStructParameter_descriptor_;
}

const RNNStructParameter& RNNStructParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

RNNStructParameter* RNNStructParameter::default_instance_ = NULL;

RNNStructParameter* RNNStructParameter::New() const {
  return new RNNStructParameter;
}

void RNNStructParameter::Clear() {
#define OFFSET_OF_FIELD_(f) (reinterpret_cast<char*>(      \
  &reinterpret_cast<RNNStructParameter*>(16)->f) - \
   reinterpret_cast<char*>(16))

#define ZR_(first, last) do {                              \
    size_t f = OFFSET_OF_FIELD_(first);                    \
    size_t n = OFFSET_OF_FIELD_(last) - f + sizeof(last);  \
    ::memset(&first, 0, n);                                \
  } while (0)

  if (_has_bits_[0 / 32] & 63) {
    ZR_(numhiddenlayers_, timeserieslength_);
  }

#undef OFFSET_OF_FIELD_
#undef ZR_

  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  mutable_unknown_fields()->Clear();
}

bool RNNStructParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.RNNStructParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional int32 numHiddenLayers = 1;
      case 1: {
        if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &numhiddenlayers_)));
          set_has_numhiddenlayers();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_hiddenLayerInputDim;
        break;
      }

      // optional int32 hiddenLayerInputDim = 2;
      case 2: {
        if (tag == 16) {
         parse_hiddenLayerInputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &hiddenlayerinputdim_)));
          set_has_hiddenlayerinputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_hiddenLayerOutputDim;
        break;
      }

      // optional int32 hiddenLayerOutputDim = 3;
      case 3: {
        if (tag == 24) {
         parse_hiddenLayerOutputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &hiddenlayeroutputdim_)));
          set_has_hiddenlayeroutputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_inputDim;
        break;
      }

      // optional int32 inputDim = 4;
      case 4: {
        if (tag == 32) {
         parse_inputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &inputdim_)));
          set_has_inputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(40)) goto parse_outputDim;
        break;
      }

      // optional int32 outputDim = 5;
      case 5: {
        if (tag == 40) {
         parse_outputDim:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &outputdim_)));
          set_has_outputdim();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(48)) goto parse_timeSeriesLength;
        break;
      }

      // optional int32 timeSeriesLength = 6;
      case 6: {
        if (tag == 48) {
         parse_timeSeriesLength:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &timeserieslength_)));
          set_has_timeserieslength();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.RNNStructParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.RNNStructParameter)
  return false;
#undef DO_
}

void RNNStructParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.RNNStructParameter)
  // optional int32 numHiddenLayers = 1;
  if (has_numhiddenlayers()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(1, this->numhiddenlayers(), output);
  }

  // optional int32 hiddenLayerInputDim = 2;
  if (has_hiddenlayerinputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->hiddenlayerinputdim(), output);
  }

  // optional int32 hiddenLayerOutputDim = 3;
  if (has_hiddenlayeroutputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->hiddenlayeroutputdim(), output);
  }

  // optional int32 inputDim = 4;
  if (has_inputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(4, this->inputdim(), output);
  }

  // optional int32 outputDim = 5;
  if (has_outputdim()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(5, this->outputdim(), output);
  }

  // optional int32 timeSeriesLength = 6;
  if (has_timeserieslength()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(6, this->timeserieslength(), output);
  }

  if (!unknown_fields().empty()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.RNNStructParameter)
}

::google::protobuf::uint8* RNNStructParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.RNNStructParameter)
  // optional int32 numHiddenLayers = 1;
  if (has_numhiddenlayers()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(1, this->numhiddenlayers(), target);
  }

  // optional int32 hiddenLayerInputDim = 2;
  if (has_hiddenlayerinputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->hiddenlayerinputdim(), target);
  }

  // optional int32 hiddenLayerOutputDim = 3;
  if (has_hiddenlayeroutputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->hiddenlayeroutputdim(), target);
  }

  // optional int32 inputDim = 4;
  if (has_inputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(4, this->inputdim(), target);
  }

  // optional int32 outputDim = 5;
  if (has_outputdim()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(5, this->outputdim(), target);
  }

  // optional int32 timeSeriesLength = 6;
  if (has_timeserieslength()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(6, this->timeserieslength(), target);
  }

  if (!unknown_fields().empty()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.RNNStructParameter)
  return target;
}

int RNNStructParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    // optional int32 numHiddenLayers = 1;
    if (has_numhiddenlayers()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->numhiddenlayers());
    }

    // optional int32 hiddenLayerInputDim = 2;
    if (has_hiddenlayerinputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->hiddenlayerinputdim());
    }

    // optional int32 hiddenLayerOutputDim = 3;
    if (has_hiddenlayeroutputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->hiddenlayeroutputdim());
    }

    // optional int32 inputDim = 4;
    if (has_inputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->inputdim());
    }

    // optional int32 outputDim = 5;
    if (has_outputdim()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->outputdim());
    }

    // optional int32 timeSeriesLength = 6;
    if (has_timeserieslength()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->timeserieslength());
    }

  }
  if (!unknown_fields().empty()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void RNNStructParameter::MergeFrom(const ::google::protobuf::Message& from) {
  GOOGLE_CHECK_NE(&from, this);
  const RNNStructParameter* source =
    ::google::protobuf::internal::dynamic_cast_if_available<const RNNStructParameter*>(
      &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void RNNStructParameter::MergeFrom(const RNNStructParameter& from) {
  GOOGLE_CHECK_NE(&from, this);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_numhiddenlayers()) {
      set_numhiddenlayers(from.numhiddenlayers());
    }
    if (from.has_hiddenlayerinputdim()) {
      set_hiddenlayerinputdim(from.hiddenlayerinputdim());
    }
    if (from.has_hiddenlayeroutputdim()) {
      set_hiddenlayeroutputdim(from.hiddenlayeroutputdim());
    }
    if (from.has_inputdim()) {
      set_inputdim(from.inputdim());
    }
    if (from.has_outputdim()) {
      set_outputdim(from.outputdim());
    }
    if (from.has_timeserieslength()) {
      set_timeserieslength(from.timeserieslength());
    }
  }
  mutable_unknown_fields()->MergeFrom(from.unknown_fields());
}

void RNNStructParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void RNNStructParameter::CopyFrom(const RNNStructParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool RNNStructParameter::IsInitialized() const {

  return true;
}

void RNNStructParameter::Swap(RNNStructParameter* other) {
  if (other != this) {
    std::swap(numhiddenlayers_, other->numhiddenlayers_);
    std::swap(hiddenlayerinputdim_, other->hiddenlayerinputdim_);
    std::swap(hiddenlayeroutputdim_, other->hiddenlayeroutputdim_);
    std::swap(inputdim_, other->inputdim_);
    std::swap(outputdim_, other->outputdim_);
    std::swap(timeserieslength_, other->timeserieslength_);
    std::swap(_has_bits_[0], other->_has_bits_[0]);
    _unknown_fields_.Swap(&other->_unknown_fields_);
    std::swap(_cached_size_, other->_cached_size_);
  }
}

::google::protobuf::Metadata RNNStructParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = RNNStructParameter_descriptor_;
  metadata.reflection = RNNStructParameter_reflection_;
  return metadata;
}


// ===================================================================

const ::google::protobuf::EnumDescriptor* NeuralNetTrainingParameter_TrainerType_descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NeuralNetTrainingParameter_TrainerType_descriptor_;
}
bool NeuralNetTrainingParameter_TrainerType_IsValid(int value) {
  switch(value) {
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#ifndef _MSC_VER
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::SGD;
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::iRProp;
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::TrainerType_MIN;
const NeuralNetTrainingParameter_TrainerType NeuralNetTrainingParameter::TrainerType_MAX;
const int NeuralNetTrainingParameter::TrainerType_ARRAYSIZE;
#endif  // _MSC_VER
#ifndef _MSC_VER
const int NeuralNetTrainingParameter::kLearningRateFieldNumber;
const int NeuralNetTrainingParameter::kMaxIterFieldNumber;
const int NeuralNetTrainingParameter::kMiniBatchSizeFieldNumber;
const int NeuralNetTrainingParameter::kNEpochFieldNumber;
const int NeuralNetTrainingParameter::kEpiFieldNumber;
const int NeuralNetTrainingParameter::kTrainerTypeFieldNumber;
const int NeuralNetTrainingParameter::kDecayRateFieldNumber;
const int NeuralNetTrainingParameter::kMomentumFieldNumber;
#endif  // !_MSC_VER

NeuralNetTrainingParameter::NeuralNetTrainingParameter()
  : ::google::protobuf::Message() {
  SharedCtor();
  // @@protoc_insertion_point(constructor:DeepLearning.NeuralNetTrainingParameter)
}

void NeuralNetTrainingParameter::InitAsDefaultInstance() {
}

NeuralNetTrainingParameter::NeuralNetTrainingParameter(const NeuralNetTrainingParameter& from)
  : ::google::protobuf::Message() {
  SharedCtor();
  MergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:DeepLearning.NeuralNetTrainingParameter)
}

void NeuralNetTrainingParameter::SharedCtor() {
  _cached_size_ = 0;
  learningrate_ = 0;
  maxiter_ = 0;
  minibatchsize_ = 0;
  nepoch_ = 0;
  epi_ = 1e-06;
  trainertype_ = 1;
  decayrate_ = 10;
  momentum_ = 0.9;
  ::memset(_has_bits_, 0, sizeof(_has_bits_));
}

NeuralNetTrainingParameter::~NeuralNetTrainingParameter() {
  // @@protoc_insertion_point(destructor:DeepLearning.NeuralNetTrainingParameter)
  SharedDtor();
}

void NeuralNetTrainingParameter::SharedDtor() {
  if (this != default_instance_) {
  }
}

void NeuralNetTrainingParameter::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* NeuralNetTrainingParameter::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return NeuralNetTrainingParameter_descriptor_;
}

const NeuralNetTrainingParameter& NeuralNetTrainingParameter::default_instance() {
  if (default_instance_ == NULL) protobuf_AddDesc_DeepLearning_2eproto();
  return *default_instance_;
}

NeuralNetTrainingParameter* NeuralNetTrainingParameter::default_instance_ = NULL;

NeuralNetTrainingParameter* NeuralNetTrainingParameter::New() const {
  return new NeuralNetTrainingParameter;
}

void NeuralNetTrainingParameter::Clear() {
#define OFFSET_OF_FIELD_(f) (reinterpret_cast<char*>(      \
  &reinterpret_cast<NeuralNetTrainingParameter*>(16)->f) - \
   reinterpret_cast<char*>(16))

#define ZR_(first, last) do {                              \
    size_t f = OFFSET_OF_FIELD_(first);                    \
    size_t n = OFFSET_OF_FIELD_(last) - f + sizeof(last);  \
    ::memset(&first, 0, n);                                \
  } while (0)

  if (_has_bits_[0 / 32] & 255) {
    ZR_(learningrate_, minibatchsize_);
    nepoch_ = 0;
    epi_ = 1e-06;
    trainertype_ = 1;
    decayrate_ = 10;
    momentum_ = 0.9;
  }

#undef OFFSET_OF_FIELD_
#undef ZR_

  ::memset(_has_bits_, 0, sizeof(_has_bits_));
  mutable_unknown_fields()->Clear();
}

bool NeuralNetTrainingParameter::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:DeepLearning.NeuralNetTrainingParameter)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional double learningRate = 1;
      case 1: {
        if (tag == 9) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &learningrate_)));
          set_has_learningrate();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_maxIter;
        break;
      }

      // optional int32 maxIter = 2;
      case 2: {
        if (tag == 16) {
         parse_maxIter:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &maxiter_)));
          set_has_maxiter();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(24)) goto parse_miniBatchSize;
        break;
      }

      // optional int32 miniBatchSize = 3;
      case 3: {
        if (tag == 24) {
         parse_miniBatchSize:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &minibatchsize_)));
          set_has_minibatchsize();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(32)) goto parse_NEpoch;
        break;
      }

      // optional int32 NEpoch = 4;
      case 4: {
        if (tag == 32) {
         parse_NEpoch:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, &nepoch_)));
          set_has_nepoch();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(41)) goto parse_epi;
        break;
      }

      // optional double epi = 5 [default = 1e-06];
      case 5: {
        if (tag == 41) {
         parse_epi:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &epi_)));
          set_has_epi();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(48)) goto parse_trainerType;
        break;
      }

      // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
      case 6: {
        if (tag == 48) {
         parse_trainerType:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          if (::DeepLearning::NeuralNetTrainingParameter_TrainerType_IsValid(value)) {
            set_trainertype(static_cast< ::DeepLearning::NeuralNetTrainingParameter_TrainerType >(value));
          } else {
            mutable_unknown_fields()->AddVarint(6, value);
          }
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(57)) goto parse_decayRate;
        break;
      }

      // optional double decayRate = 7 [default = 10];
      case 7: {
        if (tag == 57) {
         parse_decayRate:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &decayrate_)));
          set_has_decayrate();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(65)) goto parse_momentum;
        break;
      }

      // optional double momentum = 8 [default = 0.9];
      case 8: {
        if (tag == 65) {
         parse_momentum:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   double, ::google::protobuf::internal::WireFormatLite::TYPE_DOUBLE>(
                 input, &momentum_)));
          set_has_momentum();
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormat::SkipField(
              input, tag, mutable_unknown_fields()));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:DeepLearning.NeuralNetTrainingParameter)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:DeepLearning.NeuralNetTrainingParameter)
  return false;
#undef DO_
}

void NeuralNetTrainingParameter::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:DeepLearning.NeuralNetTrainingParameter)
  // optional double learningRate = 1;
  if (has_learningrate()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(1, this->learningrate(), output);
  }

  // optional int32 maxIter = 2;
  if (has_maxiter()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(2, this->maxiter(), output);
  }

  // optional int32 miniBatchSize = 3;
  if (has_minibatchsize()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(3, this->minibatchsize(), output);
  }

  // optional int32 NEpoch = 4;
  if (has_nepoch()) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32(4, this->nepoch(), output);
  }

  // optional double epi = 5 [default = 1e-06];
  if (has_epi()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(5, this->epi(), output);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
  if (has_trainertype()) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      6, this->trainertype(), output);
  }

  // optional double decayRate = 7 [default = 10];
  if (has_decayrate()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(7, this->decayrate(), output);
  }

  // optional double momentum = 8 [default = 0.9];
  if (has_momentum()) {
    ::google::protobuf::internal::WireFormatLite::WriteDouble(8, this->momentum(), output);
  }

  if (!unknown_fields().empty()) {
    ::google::protobuf::internal::WireFormat::SerializeUnknownFields(
        unknown_fields(), output);
  }
  // @@protoc_insertion_point(serialize_end:DeepLearning.NeuralNetTrainingParameter)
}

::google::protobuf::uint8* NeuralNetTrainingParameter::SerializeWithCachedSizesToArray(
    ::google::protobuf::uint8* target) const {
  // @@protoc_insertion_point(serialize_to_array_start:DeepLearning.NeuralNetTrainingParameter)
  // optional double learningRate = 1;
  if (has_learningrate()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(1, this->learningrate(), target);
  }

  // optional int32 maxIter = 2;
  if (has_maxiter()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(2, this->maxiter(), target);
  }

  // optional int32 miniBatchSize = 3;
  if (has_minibatchsize()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(3, this->minibatchsize(), target);
  }

  // optional int32 NEpoch = 4;
  if (has_nepoch()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteInt32ToArray(4, this->nepoch(), target);
  }

  // optional double epi = 5 [default = 1e-06];
  if (has_epi()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(5, this->epi(), target);
  }

  // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
  if (has_trainertype()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      6, this->trainertype(), target);
  }

  // optional double decayRate = 7 [default = 10];
  if (has_decayrate()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(7, this->decayrate(), target);
  }

  // optional double momentum = 8 [default = 0.9];
  if (has_momentum()) {
    target = ::google::protobuf::internal::WireFormatLite::WriteDoubleToArray(8, this->momentum(), target);
  }

  if (!unknown_fields().empty()) {
    target = ::google::protobuf::internal::WireFormat::SerializeUnknownFieldsToArray(
        unknown_fields(), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:DeepLearning.NeuralNetTrainingParameter)
  return target;
}

int NeuralNetTrainingParameter::ByteSize() const {
  int total_size = 0;

  if (_has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    // optional double learningRate = 1;
    if (has_learningrate()) {
      total_size += 1 + 8;
    }

    // optional int32 maxIter = 2;
    if (has_maxiter()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->maxiter());
    }

    // optional int32 miniBatchSize = 3;
    if (has_minibatchsize()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->minibatchsize());
    }

    // optional int32 NEpoch = 4;
    if (has_nepoch()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(
          this->nepoch());
    }

    // optional double epi = 5 [default = 1e-06];
    if (has_epi()) {
      total_size += 1 + 8;
    }

    // optional .DeepLearning.NeuralNetTrainingParameter.TrainerType trainerType = 6 [default = SGD];
    if (has_trainertype()) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::EnumSize(this->trainertype());
    }

    // optional double decayRate = 7 [default = 10];
    if (has_decayrate()) {
      total_size += 1 + 8;
    }

    // optional double momentum = 8 [default = 0.9];
    if (has_momentum()) {
      total_size += 1 + 8;
    }

  }
  if (!unknown_fields().empty()) {
    total_size +=
      ::google::protobuf::internal::WireFormat::ComputeUnknownFieldsSize(
        unknown_fields());
  }
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = total_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void NeuralNetTrainingParameter::MergeFrom(const ::google::protobuf::Message& from) {
  GOOGLE_CHECK_NE(&from, this);
  const NeuralNetTrainingParameter* source =
    ::google::protobuf::internal::dynamic_cast_if_available<const NeuralNetTrainingParameter*>(
      &from);
  if (source == NULL) {
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
    MergeFrom(*source);
  }
}

void NeuralNetTrainingParameter::MergeFrom(const NeuralNetTrainingParameter& from) {
  GOOGLE_CHECK_NE(&from, this);
  if (from._has_bits_[0 / 32] & (0xffu << (0 % 32))) {
    if (from.has_learningrate()) {
      set_learningrate(from.learningrate());
    }
    if (from.has_maxiter()) {
      set_maxiter(from.maxiter());
    }
    if (from.has_minibatchsize()) {
      set_minibatchsize(from.minibatchsize());
    }
    if (from.has_nepoch()) {
      set_nepoch(from.nepoch());
    }
    if (from.has_epi()) {
      set_epi(from.epi());
    }
    if (from.has_trainertype()) {
      set_trainertype(from.trainertype());
    }
    if (from.has_decayrate()) {
      set_decayrate(from.decayrate());
    }
    if (from.has_momentum()) {
      set_momentum(from.momentum());
    }
  }
  mutable_unknown_fields()->MergeFrom(from.unknown_fields());
}

void NeuralNetTrainingParameter::CopyFrom(const ::google::protobuf::Message& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void NeuralNetTrainingParameter::CopyFrom(const NeuralNetTrainingParameter& from) {
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool NeuralNetTrainingParameter::IsInitialized() const {

  return true;
}

void NeuralNetTrainingParameter::Swap(NeuralNetTrainingParameter* other) {
  if (other != this) {
    std::swap(learningrate_, other->learningrate_);
    std::swap(maxiter_, other->maxiter_);
    std::swap(minibatchsize_, other->minibatchsize_);
    std::swap(nepoch_, other->nepoch_);
    std::swap(epi_, other->epi_);
    std::swap(trainertype_, other->trainertype_);
    std::swap(decayrate_, other->decayrate_);
    std::swap(momentum_, other->momentum_);
    std::swap(_has_bits_[0], other->_has_bits_[0]);
    _unknown_fields_.Swap(&other->_unknown_fields_);
    std::swap(_cached_size_, other->_cached_size_);
  }
}

::google::protobuf::Metadata NeuralNetTrainingParameter::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = NeuralNetTrainingParameter_descriptor_;
  metadata.reflection = NeuralNetTrainingParameter_reflection_;
  return metadata;
}


// @@protoc_insertion_point(namespace_scope)

}  // namespace DeepLearning

// @@protoc_insertion_point(global_scope)
